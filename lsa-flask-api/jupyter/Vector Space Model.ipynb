{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                          impact spam exposure user engag\n",
      "1        real time algorithm detection spectacles leadi...\n",
      "2        clustering cookies identifying unique mobile d...\n",
      "3        video eog based investigation pure saccades hu...\n",
      "4        spam ham characterizing detecting fraudulent s...\n",
      "                               ...                        \n",
      "14316    hierarchical structure entropy measurement met...\n",
      "14317                 online story scheduling web advertis\n",
      "14318                       learning mixture models permut\n",
      "14319    captchas include overlapped characters project...\n",
      "14320    gets acknowledged measuring scientific contrib...\n",
      "Name: preprocessed_judul, Length: 14321, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "setD = pd.read_excel('preprocessed-dataset.xlsx',sep=',')\n",
    "query = pd.read_excel('query.xlsx',sep=',')\n",
    "#print(setD)\n",
    "Doc = setD['preprocessed_judul'].astype('str')\n",
    "print(Doc)\n",
    "# kunci = pd.read_excel('query.xlsx',sep=',')\n",
    "# query = kunci['judul'].astype('str')\n",
    "query = ['eye detection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer # tf-idf\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords # preprocessing\\\n",
    "from math import*\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "class Engine:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cosine_score = []\n",
    "        self.train_set = []  # Documents\n",
    "        self.test_set = []  # Query\n",
    "\n",
    "    def addDocument(self, word): # fungsi untuk menambahkan dokumen dataset ke dalam list train_set\n",
    "        self.train_set.append(word)\n",
    "\n",
    "    def setQuery(self, word):  # fungsi untuk menambahkan data query ke dalam list test_Set\n",
    "        self.test_set.append(word)\n",
    "\n",
    "    def process_score(self):\n",
    "        stopWords = stopwords.words('english') \n",
    "        vectorizer = CountVectorizer()\n",
    "\n",
    "        transformer = TfidfTransformer()\n",
    "\n",
    "        trainVectorizerArray = vectorizer.fit_transform(self.train_set).toarray() \n",
    "        # menghitung Bobot dokumen dataset dan uji dan kemudian disimpan dalam bentuk array \n",
    "        testVectorizerArray = vectorizer.transform(self.test_set).toarray()\n",
    "\n",
    "        cx = lambda a, b: round(np.inner(a, b) / (LA.norm(a) * LA.norm(b)), 3) \n",
    "        #fungsi tanpa nama untuk normalisasi data dan definisi rumus Cosine Similarity \n",
    "        #         print testVectorizerArray\n",
    "        output = []\n",
    "        for i in range(0, len(testVectorizerArray)):\n",
    "            output.append([])\n",
    "\n",
    "        for vector in trainVectorizerArray:\n",
    "            # print vector\n",
    "            u = 0\n",
    "            for testV in testVectorizerArray:\n",
    "                #perhitungan Cosine Similarity dalam bentuk vector dari dataset dengan query\n",
    "                #yang di masukan yang kemudian mengembalikan nilai cosine ke dalam variable\n",
    "                #cosine_score dalam bentuk list.\n",
    "                # print testV\n",
    "                cosine = cx(vector, testV)\n",
    "                #                 self.cosine_score.append(cosine)\n",
    "                #                 bulatin = (round(cosine),2)\n",
    "                output[u].append((cosine))\n",
    "                u = u + 1\n",
    "        return output\n",
    "        # return testVectorizerArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc = setD['prerpocessing'].astype('str')\n",
    "Qdoc = queries['queriespripo'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eye detection</th>\n",
       "      <th>Documents</th>\n",
       "      <th>Abstrak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_1</td>\n",
       "      <td>paper quantify effect unsolicited emails spam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500</td>\n",
       "      <td>Document_2</td>\n",
       "      <td>eye detection plays important role many intell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_3</td>\n",
       "      <td>embodiments directed towards clustering cookie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_4</td>\n",
       "      <td>human computer interaction hci methodology com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_5</td>\n",
       "      <td>web mail providers rely users vote quickly col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_6</td>\n",
       "      <td>many large internet websites accessed users an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_7</td>\n",
       "      <td>random walk important tool many graph mining a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_8</td>\n",
       "      <td>paper analyzes performance haarlike feature ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.250</td>\n",
       "      <td>Document_9</td>\n",
       "      <td>paper proposes system onboard monitoring loss ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_10</td>\n",
       "      <td>users digital libraries usually want know exac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.267</td>\n",
       "      <td>Document_11</td>\n",
       "      <td>context education technology empathic interact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_12</td>\n",
       "      <td>embodiments presented herein provide methods s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_13</td>\n",
       "      <td>image captcha one images challenge correct ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14</td>\n",
       "      <td>user votes important signals community questio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_15</td>\n",
       "      <td>paper considers wellstudied problem clustering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_16</td>\n",
       "      <td>computation tree logic ctl one syntactically e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_17</td>\n",
       "      <td>latent semantic indexing classical method prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_18</td>\n",
       "      <td>last decade email spam evolved irritant users ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_19</td>\n",
       "      <td>study two natural variations set disjointness ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_20</td>\n",
       "      <td>disclosed herein method systems architectures ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_21</td>\n",
       "      <td>web pagesespecially dynamically generated ones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_22</td>\n",
       "      <td>paper consider problem devising blocking schem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_23</td>\n",
       "      <td>study problem diverse feature selection linear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_24</td>\n",
       "      <td>embodiments directed towards employing playful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_25</td>\n",
       "      <td>propose new optimization framework summarizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_26</td>\n",
       "      <td>people assess social environments plays centra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_27</td>\n",
       "      <td>paper analyze second eigenvector technique spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_28</td>\n",
       "      <td>networks characterized nodes edges spate recen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_29</td>\n",
       "      <td>paper delves recently proposed technique colla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_30</td>\n",
       "      <td>onboard monitoring alertness level automotive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14291</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14292</td>\n",
       "      <td>random projection rp powerful dimension reduct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14292</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14293</td>\n",
       "      <td>many modern applications ai web search mobile ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14293</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14294</td>\n",
       "      <td>named entity disambiguation ned central proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14294</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14295</td>\n",
       "      <td>paper introduce system named portable personal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14295</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14296</td>\n",
       "      <td>large body work devoted identifying communitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14296</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14297</td>\n",
       "      <td>user feedback vital quality collaborative spam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14297</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14298</td>\n",
       "      <td>paper presents brief review lagrangianhamilton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14298</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14299</td>\n",
       "      <td>present mixture model based approach learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14300</td>\n",
       "      <td>social systems information often exists disper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14300</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14301</td>\n",
       "      <td>central question conclusions main text extent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14301</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14302</td>\n",
       "      <td>order improve rbac first define trust trust wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14302</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14303</td>\n",
       "      <td>techniques described herein providing marketpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14303</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14304</td>\n",
       "      <td>improved system method provided feature select...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14304</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14305</td>\n",
       "      <td>techniques provided improving speed accuracy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14305</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14306</td>\n",
       "      <td>coclustering simultaneous partitioning rows co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14306</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14307</td>\n",
       "      <td>method system programs computing similarity in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14307</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14308</td>\n",
       "      <td>given distributed data streams 1 dots consider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14308</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14309</td>\n",
       "      <td>set function ground set size n approximately m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14309</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14310</td>\n",
       "      <td>tables ubiquitous digital libraries scientific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14310</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14311</td>\n",
       "      <td>methods system optimally allocating ad space a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14311</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14312</td>\n",
       "      <td>method apparatus provided identifying two webs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14312</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14313</td>\n",
       "      <td>embodiments present inversion relate twopass c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14313</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14314</td>\n",
       "      <td>accordance one aspect methods apparatus facili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14314</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14315</td>\n",
       "      <td>system method implementing multistep challenge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14315</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14316</td>\n",
       "      <td>mallows model classical model generating noisy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14316</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14317</td>\n",
       "      <td>methods apparatuses provided accessing taxonom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14317</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14318</td>\n",
       "      <td>study online job scheduling problem motivated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14318</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14319</td>\n",
       "      <td>paper consider problem learning mixture permut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14319</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14320</td>\n",
       "      <td>techniques described herein generating captcha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14320</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Document_14321</td>\n",
       "      <td>acknowledgments research publications like cit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14321 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       eye detection       Documents  \\\n",
       "0              0.000      Document_1   \n",
       "1              0.500      Document_2   \n",
       "2              0.000      Document_3   \n",
       "3              0.000      Document_4   \n",
       "4              0.000      Document_5   \n",
       "5              0.000      Document_6   \n",
       "6              0.000      Document_7   \n",
       "7              0.000      Document_8   \n",
       "8              0.250      Document_9   \n",
       "9              0.000     Document_10   \n",
       "10             0.267     Document_11   \n",
       "11             0.000     Document_12   \n",
       "12             0.000     Document_13   \n",
       "13             0.000     Document_14   \n",
       "14             0.000     Document_15   \n",
       "15             0.000     Document_16   \n",
       "16             0.000     Document_17   \n",
       "17             0.000     Document_18   \n",
       "18             0.000     Document_19   \n",
       "19             0.000     Document_20   \n",
       "20             0.000     Document_21   \n",
       "21             0.000     Document_22   \n",
       "22             0.000     Document_23   \n",
       "23             0.000     Document_24   \n",
       "24             0.000     Document_25   \n",
       "25             0.000     Document_26   \n",
       "26             0.000     Document_27   \n",
       "27             0.000     Document_28   \n",
       "28             0.000     Document_29   \n",
       "29             0.000     Document_30   \n",
       "...              ...             ...   \n",
       "14291          0.000  Document_14292   \n",
       "14292          0.000  Document_14293   \n",
       "14293          0.000  Document_14294   \n",
       "14294          0.000  Document_14295   \n",
       "14295          0.000  Document_14296   \n",
       "14296          0.000  Document_14297   \n",
       "14297          0.000  Document_14298   \n",
       "14298          0.000  Document_14299   \n",
       "14299          0.000  Document_14300   \n",
       "14300          0.000  Document_14301   \n",
       "14301          0.000  Document_14302   \n",
       "14302          0.000  Document_14303   \n",
       "14303          0.000  Document_14304   \n",
       "14304          0.000  Document_14305   \n",
       "14305          0.000  Document_14306   \n",
       "14306          0.000  Document_14307   \n",
       "14307          0.000  Document_14308   \n",
       "14308          0.000  Document_14309   \n",
       "14309          0.000  Document_14310   \n",
       "14310          0.000  Document_14311   \n",
       "14311          0.000  Document_14312   \n",
       "14312          0.000  Document_14313   \n",
       "14313          0.000  Document_14314   \n",
       "14314          0.000  Document_14315   \n",
       "14315          0.000  Document_14316   \n",
       "14316          0.000  Document_14317   \n",
       "14317          0.000  Document_14318   \n",
       "14318          0.000  Document_14319   \n",
       "14319          0.000  Document_14320   \n",
       "14320          0.000  Document_14321   \n",
       "\n",
       "                                                 Abstrak  \n",
       "0      paper quantify effect unsolicited emails spam ...  \n",
       "1      eye detection plays important role many intell...  \n",
       "2      embodiments directed towards clustering cookie...  \n",
       "3      human computer interaction hci methodology com...  \n",
       "4      web mail providers rely users vote quickly col...  \n",
       "5      many large internet websites accessed users an...  \n",
       "6      random walk important tool many graph mining a...  \n",
       "7      paper analyzes performance haarlike feature ba...  \n",
       "8      paper proposes system onboard monitoring loss ...  \n",
       "9      users digital libraries usually want know exac...  \n",
       "10     context education technology empathic interact...  \n",
       "11     embodiments presented herein provide methods s...  \n",
       "12     image captcha one images challenge correct ans...  \n",
       "13     user votes important signals community questio...  \n",
       "14     paper considers wellstudied problem clustering...  \n",
       "15     computation tree logic ctl one syntactically e...  \n",
       "16     latent semantic indexing classical method prod...  \n",
       "17     last decade email spam evolved irritant users ...  \n",
       "18     study two natural variations set disjointness ...  \n",
       "19     disclosed herein method systems architectures ...  \n",
       "20     web pagesespecially dynamically generated ones...  \n",
       "21     paper consider problem devising blocking schem...  \n",
       "22     study problem diverse feature selection linear...  \n",
       "23     embodiments directed towards employing playful...  \n",
       "24     propose new optimization framework summarizati...  \n",
       "25     people assess social environments plays centra...  \n",
       "26     paper analyze second eigenvector technique spe...  \n",
       "27     networks characterized nodes edges spate recen...  \n",
       "28     paper delves recently proposed technique colla...  \n",
       "29     onboard monitoring alertness level automotive ...  \n",
       "...                                                  ...  \n",
       "14291  random projection rp powerful dimension reduct...  \n",
       "14292  many modern applications ai web search mobile ...  \n",
       "14293  named entity disambiguation ned central proble...  \n",
       "14294  paper introduce system named portable personal...  \n",
       "14295  large body work devoted identifying communitie...  \n",
       "14296  user feedback vital quality collaborative spam...  \n",
       "14297  paper presents brief review lagrangianhamilton...  \n",
       "14298  present mixture model based approach learning ...  \n",
       "14299  social systems information often exists disper...  \n",
       "14300  central question conclusions main text extent ...  \n",
       "14301  order improve rbac first define trust trust wo...  \n",
       "14302  techniques described herein providing marketpl...  \n",
       "14303  improved system method provided feature select...  \n",
       "14304  techniques provided improving speed accuracy a...  \n",
       "14305  coclustering simultaneous partitioning rows co...  \n",
       "14306  method system programs computing similarity in...  \n",
       "14307  given distributed data streams 1 dots consider...  \n",
       "14308  set function ground set size n approximately m...  \n",
       "14309  tables ubiquitous digital libraries scientific...  \n",
       "14310  methods system optimally allocating ad space a...  \n",
       "14311  method apparatus provided identifying two webs...  \n",
       "14312  embodiments present inversion relate twopass c...  \n",
       "14313  accordance one aspect methods apparatus facili...  \n",
       "14314  system method implementing multistep challenge...  \n",
       "14315  mallows model classical model generating noisy...  \n",
       "14316  methods apparatuses provided accessing taxonom...  \n",
       "14317  study online job scheduling problem motivated ...  \n",
       "14318  paper consider problem learning mixture permut...  \n",
       "14319  techniques described herein generating captcha...  \n",
       "14320  acknowledgments research publications like cit...  \n",
       "\n",
       "[14321 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = Engine()\n",
    "\n",
    "docs = [str(x) for x in Doc]\n",
    "documentNames = list()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    engine.addDocument(doc) \n",
    "    documentNames.append(\"Document_{}\".format(i+1))\n",
    "for queries in Qdoc:\n",
    "    engine.setQuery(queries) #inputandata uji\n",
    "\n",
    "titles_score = engine.process_score()\n",
    "ScoreDf = (pd.DataFrame(titles_score)).T\n",
    "ScoreDf.columns = query\n",
    "ScoreDf[\"Documents\"] = documentNames\n",
    "ScoreDf[\"Abstrak\"] = setD[\"preprocessed_abstrak\"].values\n",
    "ScoreDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "#svm_ = svm.SVC(kernel='linear')\n",
    "df_listed = list()\n",
    "for i in query:\n",
    "    labels = list()\n",
    "    #labelss = list()\n",
    "    for j in ScoreDf[i]:\n",
    "        if j>0.000:\n",
    "            labels.append(1)\n",
    "            #labelss.append(cross_val_score(svm_, query, Doc, cv=10)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "            #labelss.append(cross_val_score(svm_, query, Doc, cv=10)\n",
    "    datadf = pd.DataFrame(ScoreDf[i])\n",
    "    datadf['Documents'] = ScoreDf['Documents']\n",
    "    datadf['Labels'] = labels\n",
    "    datadf['abstrak'] = ScoreDf['Abstrak'].values\n",
    "    datadf['reviewer'] = setD['Reviewer'].values\n",
    "    datadf['Judul'] = setD['Judul'].values\n",
    "    df_listed.append(datadf.sort_values(by=[i], ascending=False))\n",
    "#df_listed\n",
    "#df_listed[0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Waktu Proses  0.0  Detik.\n"
     ]
    }
   ],
   "source": [
    "#import urllib2  \n",
    "import time  \n",
    "awal = time.time()\n",
    "df_listed[0].head(10) \n",
    "akhir = time.time()  \n",
    "print (\"Total Waktu Proses \", akhir- awal, \" Detik.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
