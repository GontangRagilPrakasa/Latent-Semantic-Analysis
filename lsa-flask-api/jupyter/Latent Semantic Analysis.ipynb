{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Waktu Proses  0.0009987354278564453  Detik.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer # tf-idf\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords # preprocessing\\\n",
    "import math\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "class Engine:\n",
    "    def __init__(self):\n",
    "        self.cosine_score = []\n",
    "        self.train_set = []  # Documents\n",
    "        self.test_set = []  # Query\n",
    "\n",
    "    def addDocument(self, word): # fungsi untuk menambahkan dokumen dataset ke dalam list train_set\n",
    "        self.train_set.append(word)\n",
    "\n",
    "    def setQuery(self, word):  # fungsi untuk menambahkan data query ke dalam list test_Set\n",
    "        self.test_set.append(word)\n",
    "\n",
    "    def process_score(self):\n",
    "        vectorizer = TfidfVectorizer(stop_words='english', max_features= 1000, max_df = 0.5, smooth_idf=True)\n",
    "        svd_model = TruncatedSVD(n_components=100,algorithm='randomized',n_iter=10)\n",
    "        lsa = Pipeline([('tfidf', vectorizer),('svd', svd_model)])\n",
    "        #print(lsa)\n",
    "        #transformer = TfidfTransformer(stop_words='english', use_idf=True, smooth_idf=True)\n",
    "\n",
    "        trainVectorizerArray = lsa.fit_transform(self.train_set).tolist() \n",
    "        # menghitung Bobot dokumen dataset dan uji dan kemudian disimpan dalam bentuk array \n",
    "        testVectorizerArray = lsa.transform(self.test_set).tolist()\n",
    "\n",
    "        cx = lambda a, b: round(np.inner(a, b) / (LA.norm(a) * LA.norm(b)), 3) \n",
    "        #fungsi tanpa nama untuk normalisasi data dan definisi rumus Cosine Similarity \n",
    "        #print (testVectorizerArray)\n",
    "        output = []\n",
    "        for i in range(0, len(testVectorizerArray)):\n",
    "            output.append([])\n",
    "\n",
    "        for vector in trainVectorizerArray:\n",
    "            #print (vector)\n",
    "            u = 0\n",
    "            for testV in testVectorizerArray:\n",
    "                #perhitungan Cosine Similarity dalam bentuk vector dari dataset dengan query\n",
    "                #yang di masukan yang kemudian mengembalikan nilai cosine ke dalam variable\n",
    "                #cosine_score dalam bentuk list.\n",
    "                #print (testV)\n",
    "                cosine = cx(vector, testV)\n",
    "                #print(cosine)\n",
    "                #                 self.cosine_score.append(cosine)\n",
    "                #                 bulatin = (round(cosine),2)\n",
    "                if math.isnan(cosine):\n",
    "                    cosine = 0\n",
    "                output[u].append((cosine))\n",
    "                u = u + 1\n",
    "        return output\n",
    "        #return testVectorizerArray\n",
    "        \n",
    "import pandas as pd\n",
    "setD = pd.read_excel('preprocessed-dataset.xlsx',sep=',')\n",
    "#print(setD)\n",
    "Doc = setD['preprocessed_judul'].astype('str')\n",
    "#print(Doc)\n",
    "# kunci = pd.read_excel('query.xlsx',sep=',')\n",
    "# query = kunci['judul'].astype('str')\n",
    "query = ['eye detection']\n",
    "        \n",
    "engine = Engine()\n",
    "\n",
    "docs = [str(x) for x in Doc]\n",
    "documentNames = list()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    engine.addDocument(doc) \n",
    "    documentNames.append(\"Document_{}\".format(i+1))\n",
    "for queries in query:\n",
    "    engine.setQuery(queries) #inputandata uji\n",
    "\n",
    "titles_score = engine.process_score()\n",
    "ScoreDf = (pd.DataFrame(titles_score)).T\n",
    "ScoreDf.columns = query\n",
    "ScoreDf[\"Documents\"] = documentNames\n",
    "ScoreDf[\"Abstrak\"] = setD[\"preprocessed_abstrak\"].values\n",
    "ScoreDf\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "#svm_ = svm.SVC(kernel='linear')\n",
    "df_listed = list()\n",
    "for i in query:\n",
    "    labels = list()\n",
    "    #labelss = list()\n",
    "    for j in ScoreDf[i]:\n",
    "        if j>0.000:\n",
    "            labels.append(1)\n",
    "            #labelss.append(cross_val_score(svm_, query, Doc, cv=10)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "            #labelss.append(cross_val_score(svm_, query, Doc, cv=10)\n",
    "    datadf = pd.DataFrame(ScoreDf[i])\n",
    "    datadf['Documents'] = ScoreDf['Documents']\n",
    "    datadf['Labels'] = labels\n",
    "    datadf['abstrak'] = ScoreDf['Abstrak'].values\n",
    "    datadf['reviewer'] = setD['Reviewer'].values\n",
    "    datadf['Judul'] = setD['Judul'].values\n",
    "    df_listed.append(datadf.sort_values(by=[i], ascending=False))\n",
    "#df_listed\n",
    "#df_listed[0].head(5)\n",
    "#import urllib2  \n",
    "import time  \n",
    "awal = time.time()\n",
    "df_listed[0].head(10) \n",
    "akhir = time.time()  \n",
    "print (\"Total Waktu Proses \", akhir- awal, \" Detik.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eye detection</th>\n",
       "      <th>Documents</th>\n",
       "      <th>Labels</th>\n",
       "      <th>abstrak</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>Judul</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>1.000</td>\n",
       "      <td>Document_2094</td>\n",
       "      <td>1</td>\n",
       "      <td>develop novel framework pagelevel template det...</td>\n",
       "      <td>deepayan chakrabarti</td>\n",
       "      <td>page-level template detection via isotonic smo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>1.000</td>\n",
       "      <td>Document_4295</td>\n",
       "      <td>1</td>\n",
       "      <td>system method business method operating comput...</td>\n",
       "      <td>rakesh agrawal</td>\n",
       "      <td>deadlock detection is cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.000</td>\n",
       "      <td>Document_331</td>\n",
       "      <td>1</td>\n",
       "      <td>advances gps tracking technology enabled us in...</td>\n",
       "      <td>hui xiong</td>\n",
       "      <td>a taxi driving fraud detection system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>1.000</td>\n",
       "      <td>Document_8711</td>\n",
       "      <td>1</td>\n",
       "      <td>develop novel framework pagelevel template det...</td>\n",
       "      <td>ravi kumar</td>\n",
       "      <td>page-level template detection via isotonic smo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>1.000</td>\n",
       "      <td>Document_3473</td>\n",
       "      <td>1</td>\n",
       "      <td>visual fashion analysis attracted many attenti...</td>\n",
       "      <td>ping luo</td>\n",
       "      <td>fashion landmark detection in the wild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815</th>\n",
       "      <td>0.996</td>\n",
       "      <td>Document_6816</td>\n",
       "      <td>1</td>\n",
       "      <td>proliferation malware presented serious threat...</td>\n",
       "      <td>tao li</td>\n",
       "      <td>imds: intelligent malware detection system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>0.996</td>\n",
       "      <td>Document_2590</td>\n",
       "      <td>1</td>\n",
       "      <td>paper introduces minnesota intrusion detection...</td>\n",
       "      <td>pang-ning  tan</td>\n",
       "      <td>minds-minnesota intrusion detection system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10249</th>\n",
       "      <td>0.996</td>\n",
       "      <td>Document_10250</td>\n",
       "      <td>1</td>\n",
       "      <td>paper introduces minnesota intrusion detection...</td>\n",
       "      <td>vipin kumar</td>\n",
       "      <td>minds-minnesota intrusion detection system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7793</th>\n",
       "      <td>0.994</td>\n",
       "      <td>Document_7794</td>\n",
       "      <td>1</td>\n",
       "      <td>detection tracking people lie heart many curre...</td>\n",
       "      <td>ying li</td>\n",
       "      <td>detection and tracking in the ibm peoplevision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.992</td>\n",
       "      <td>Document_399</td>\n",
       "      <td>1</td>\n",
       "      <td>unprecedented speed virulence sophistication s...</td>\n",
       "      <td>xingquan zhu</td>\n",
       "      <td>veye: behavioral footprinting for self-propaga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eye detection       Documents  Labels  \\\n",
       "2093           1.000   Document_2094       1   \n",
       "4294           1.000   Document_4295       1   \n",
       "330            1.000    Document_331       1   \n",
       "8710           1.000   Document_8711       1   \n",
       "3472           1.000   Document_3473       1   \n",
       "6815           0.996   Document_6816       1   \n",
       "2589           0.996   Document_2590       1   \n",
       "10249          0.996  Document_10250       1   \n",
       "7793           0.994   Document_7794       1   \n",
       "398            0.992    Document_399       1   \n",
       "\n",
       "                                                 abstrak  \\\n",
       "2093   develop novel framework pagelevel template det...   \n",
       "4294   system method business method operating comput...   \n",
       "330    advances gps tracking technology enabled us in...   \n",
       "8710   develop novel framework pagelevel template det...   \n",
       "3472   visual fashion analysis attracted many attenti...   \n",
       "6815   proliferation malware presented serious threat...   \n",
       "2589   paper introduces minnesota intrusion detection...   \n",
       "10249  paper introduces minnesota intrusion detection...   \n",
       "7793   detection tracking people lie heart many curre...   \n",
       "398    unprecedented speed virulence sophistication s...   \n",
       "\n",
       "                   reviewer                                              Judul  \n",
       "2093   deepayan chakrabarti  page-level template detection via isotonic smo...  \n",
       "4294         rakesh agrawal                        deadlock detection is cheap  \n",
       "330               hui xiong              a taxi driving fraud detection system  \n",
       "8710             ravi kumar  page-level template detection via isotonic smo...  \n",
       "3472               ping luo             fashion landmark detection in the wild  \n",
       "6815                 tao li         imds: intelligent malware detection system  \n",
       "2589         pang-ning  tan         minds-minnesota intrusion detection system  \n",
       "10249           vipin kumar         minds-minnesota intrusion detection system  \n",
       "7793                ying li  detection and tracking in the ibm peoplevision...  \n",
       "398            xingquan zhu  veye: behavioral footprinting for self-propaga...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_listed[0].head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
