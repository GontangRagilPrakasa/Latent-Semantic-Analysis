{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as LA # operasi baris elementer\n",
    "from scipy.sparse import linalg\n",
    "from openpyxl import load_workbook # load data excel\n",
    "from sklearn.feature_extraction.text import CountVectorizer # tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer # tf-idf\n",
    "from sklearn.metrics.pairwise import cosine_similarity # cosine similarity\n",
    "from nltk.corpus import stopwords # preprocessing\n",
    "from nltk.stem import PorterStemmer # preprocessing bahasa inggris\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory  # preprocessing\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory #preprocessing\n",
    "import string # ya buat string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judul</th>\n",
       "      <th>Reviewer</th>\n",
       "      <th>Abstrak</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>preprocessed_judul</th>\n",
       "      <th>preprocessed_abstrak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>impact of spam exposure on user engagement.</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>In this paper we quantify the effect of unsoli...</td>\n",
       "      <td>impact spam exposure user engagement</td>\n",
       "      <td>impact spam exposure user engag</td>\n",
       "      <td>paper quantify effect unsolicited emails spam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a real time algorithm for detection of spectac...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Eye detection plays an important role in many ...</td>\n",
       "      <td>real time algorithm detection spectacle lead e...</td>\n",
       "      <td>real time algorithm detection spectacles leadi...</td>\n",
       "      <td>eye detection plays important role many intell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clustering cookies for identifying unique mobi...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Embodiments are directed towards clustering co...</td>\n",
       "      <td>cluster cooky identify unique mobile device</td>\n",
       "      <td>clustering cookies identifying unique mobile d...</td>\n",
       "      <td>embodiments directed towards clustering cookie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video &amp; eog based investigation of pure saccad...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Human Computer Interaction (HCI) is the method...</td>\n",
       "      <td>video    eog base investigation pure saccade h...</td>\n",
       "      <td>video eog based investigation pure saccades hu...</td>\n",
       "      <td>human computer interaction hci methodology com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam or ham?: characterizing and detecting fra...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Web mail providers rely on users to\\\" vote\\\" t...</td>\n",
       "      <td>spam    characterize detect fraudulent spam re...</td>\n",
       "      <td>spam ham characterizing detecting fraudulent s...</td>\n",
       "      <td>web mail providers rely users vote quickly col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>overcoming browser cookie churn with clustering</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Many large Internet websites are accessed by u...</td>\n",
       "      <td>overcome browser cookie churn cluster</td>\n",
       "      <td>overcoming browser cookie churn clust</td>\n",
       "      <td>many large internet websites accessed users an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>on sampling nodes in a network</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Random walk is an important tool in many graph...</td>\n",
       "      <td>sample node network</td>\n",
       "      <td>sampling nodes network</td>\n",
       "      <td>random walk important tool many graph mining a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>analysis of training parameters for classifier...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>This paper analyzes the performance of the Haa...</td>\n",
       "      <td>analysis train parameter classifier base featu...</td>\n",
       "      <td>analysis training parameters classifiers based...</td>\n",
       "      <td>paper analyzes performance haarlike feature ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>an on-board vision based system for drowsiness...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>This paper proposes a system for on-board moni...</td>\n",
       "      <td>board vision base drowsiness detection automot...</td>\n",
       "      <td>onboard vision based system drowsiness detecti...</td>\n",
       "      <td>paper proposes system onboard monitoring loss ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>disambiguating authors in academic publication...</td>\n",
       "      <td>c. lee giles</td>\n",
       "      <td>Users of digital libraries usually want to kno...</td>\n",
       "      <td>disambiguate author academic publication rando...</td>\n",
       "      <td>disambiguating authors academic publications u...</td>\n",
       "      <td>users digital libraries usually want know exac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>automated alertness and emotion detection for ...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>In the context of education technology, empath...</td>\n",
       "      <td>automate alertness emotion detection empathic ...</td>\n",
       "      <td>automated alertness emotion detection empathic...</td>\n",
       "      <td>context education technology empathic interact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>system and method for counting network users</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Embodiments presented herein provide methods, ...</td>\n",
       "      <td>method count network user</td>\n",
       "      <td>system method counting network us</td>\n",
       "      <td>embodiments presented herein provide methods s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>constructing image captchas utilizing private ...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>An image CAPTCHA having one or more images, a ...</td>\n",
       "      <td>construct image captchas utilize private image</td>\n",
       "      <td>constructing image captchas utilizing private ...</td>\n",
       "      <td>image captcha one images challenge correct ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vote calibration in community question-answeri...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>User votes are important signals in community ...</td>\n",
       "      <td>vote calibration community question answer</td>\n",
       "      <td>vote calibration community questionanswering s...</td>\n",
       "      <td>user votes important signals community questio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spectral clustering with limited independence</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>This paper considers the well-studied problem ...</td>\n",
       "      <td>spectral cluster limit independence</td>\n",
       "      <td>spectral clustering limited independ</td>\n",
       "      <td>paper considers wellstudied problem clustering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>quantified computation tree logic</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Computation Tree Logic (CTL) is one of the mos...</td>\n",
       "      <td>quantify computation tree logic</td>\n",
       "      <td>quantified computation tree log</td>\n",
       "      <td>computation tree logic ctl one syntactically e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>variable latent semantic indexing</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Latent Semantic Indexing is a classical method...</td>\n",
       "      <td>variable latent semantic</td>\n",
       "      <td>variable latent semantic index</td>\n",
       "      <td>latent semantic indexing classical method prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>enhanced email spam filtering through combinin...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Over the last decade Email Spam has evolved fr...</td>\n",
       "      <td>enhance email spam filter combine similarity g...</td>\n",
       "      <td>enhanced email spam filtering combining simila...</td>\n",
       "      <td>last decade email spam evolved irritant users ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sparse and lopsided set disjointness via infor...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>We study two natural variations of the set dis...</td>\n",
       "      <td>sparse lopsided set disjointness theory</td>\n",
       "      <td>sparse lopsided set disjointness via informati...</td>\n",
       "      <td>study two natural variations set disjointness ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>systems and methods of universal resource loca...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Disclosed herein are method, systems and archi...</td>\n",
       "      <td>method universal resource locator normalization</td>\n",
       "      <td>systems methods universal resource locator norm</td>\n",
       "      <td>disclosed herein method systems architectures ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>automatic identification of informative sectio...</td>\n",
       "      <td>c. lee giles</td>\n",
       "      <td>Web pages-especially dynamically generated one...</td>\n",
       "      <td>automatic identification informative web</td>\n",
       "      <td>automatic identification informative sections ...</td>\n",
       "      <td>web pagesespecially dynamically generated ones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>optimal hashing schemes for entity matching</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>In this paper, we consider the problem of devi...</td>\n",
       "      <td>optimal hash scheme entity match</td>\n",
       "      <td>optimal hashing schemes entity match</td>\n",
       "      <td>paper consider problem devising blocking schem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>selecting diverse features via spectral regula...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>We study the problem of diverse feature select...</td>\n",
       "      <td>select diverse feature spectral regularization</td>\n",
       "      <td>selecting diverse features via spectral regular</td>\n",
       "      <td>study problem diverse feature selection linear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>playful incentive for labeling content</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Embodiments are directed towards employing a p...</td>\n",
       "      <td>playful incentive label content</td>\n",
       "      <td>playful incentive labeling cont</td>\n",
       "      <td>embodiments directed towards employing playful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>summarization through submodularity and disper...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>We propose a new optimization framework for su...</td>\n",
       "      <td>summarization submodularity dispersion</td>\n",
       "      <td>summarization submodularity dispers</td>\n",
       "      <td>propose new optimization framework summarizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>social sampling</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>How people assess their social environments pl...</td>\n",
       "      <td>social sample</td>\n",
       "      <td>social sampl</td>\n",
       "      <td>people assess social environments plays centra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>spectral clustering by recursive partitioning</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>In this paper, we analyze the second eigenvect...</td>\n",
       "      <td>spectral cluster recursive partition</td>\n",
       "      <td>spectral clustering recursive partit</td>\n",
       "      <td>paper analyze second eigenvector technique spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>on estimating the average degree</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Networks are characterized by nodes and edges....</td>\n",
       "      <td>estimate average degree</td>\n",
       "      <td>estimating average degre</td>\n",
       "      <td>networks characterized nodes edges spate recen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>collaborative email-spam filtering with the ha...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>This paper delves into a recently proposed tec...</td>\n",
       "      <td>collaborative email spam filter hash trick</td>\n",
       "      <td>collaborative emailspam filtering hashing trick</td>\n",
       "      <td>paper delves recently proposed technique colla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>a vision-based system for monitoring the loss ...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Onboard monitoring of the alertness level of a...</td>\n",
       "      <td>vision base monitor loss attention automotive ...</td>\n",
       "      <td>visionbased system monitoring loss attention a...</td>\n",
       "      <td>onboard monitoring alertness level automotive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14291</th>\n",
       "      <td>random projections in gravitational wave searc...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Random projection (RP) is a powerful dimension...</td>\n",
       "      <td>random projection gravitational wave search co...</td>\n",
       "      <td>random projections gravitational wave searches...</td>\n",
       "      <td>random projection rp powerful dimension reduct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14292</th>\n",
       "      <td>an evaluation of multi-probe locality sensitiv...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Many modern applications of AI such as web sea...</td>\n",
       "      <td>evaluation multi probe locality sensitive hash...</td>\n",
       "      <td>evaluation multiprobe locality sensitive hashi...</td>\n",
       "      <td>many modern applications ai web search mobile ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14293</th>\n",
       "      <td>task-specific representation learning for web-...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Named entity disambiguation (NED) is a central...</td>\n",
       "      <td>task specific representation learn web scale e...</td>\n",
       "      <td>taskspecific representation learning webscale ...</td>\n",
       "      <td>named entity disambiguation ned central proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14294</th>\n",
       "      <td>a portable personality recognizer based on aff...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>In this paper, we introduce a system named Por...</td>\n",
       "      <td>portable personality recognizer base affective...</td>\n",
       "      <td>portable personality recognizer based affectiv...</td>\n",
       "      <td>paper introduce system named portable personal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14295</th>\n",
       "      <td>diminishing communities in large social and in...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>A large body of work has been devoted to ident...</td>\n",
       "      <td>diminish community large social network</td>\n",
       "      <td>diminishing communities large social informati...</td>\n",
       "      <td>large body work devoted identifying communitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14296</th>\n",
       "      <td>collaborative spam filtering with the hashing ...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>User feedback is vital to the quality of the c...</td>\n",
       "      <td>collaborative spam filter hash trick</td>\n",
       "      <td>collaborative spam filtering hashing trick</td>\n",
       "      <td>user feedback vital quality collaborative spam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14297</th>\n",
       "      <td>a review on extension of lagrangian-hamiltonia...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>This paper presents a brief review on Lagrangi...</td>\n",
       "      <td>review extension lagrangian hamiltonian mechanic</td>\n",
       "      <td>review extension lagrangianhamiltonian mechan</td>\n",
       "      <td>paper presents brief review lagrangianhamilton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14298</th>\n",
       "      <td>probabilistic user behavior models</td>\n",
       "      <td>c. lee giles</td>\n",
       "      <td>We present a mixture model based approach for ...</td>\n",
       "      <td>probabilistic user behavior model</td>\n",
       "      <td>probabilistic user behavior model</td>\n",
       "      <td>present mixture model based approach learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>aggregating information from the crowd and the...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>In social systems, information often exists in...</td>\n",
       "      <td>aggregate crowd network</td>\n",
       "      <td>aggregating information crowd network</td>\n",
       "      <td>social systems information often exists disper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14300</th>\n",
       "      <td>supplementary material: large-scale community ...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>A central question for our conclusions in the ...</td>\n",
       "      <td>supplementary material large scale community s...</td>\n",
       "      <td>supplementary material largescale community st...</td>\n",
       "      <td>central question conclusions main text extent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14301</th>\n",
       "      <td>user trustworthiness</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>In order to improve RBAC, first we define trus...</td>\n",
       "      <td>user trustworthiness</td>\n",
       "      <td>user trustworthi</td>\n",
       "      <td>order improve rbac first define trust trust wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14302</th>\n",
       "      <td>marketplace for captcha developers</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Techniques are described herein for providing ...</td>\n",
       "      <td>marketplace captcha developer</td>\n",
       "      <td>marketplace captcha develop</td>\n",
       "      <td>techniques described herein providing marketpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14303</th>\n",
       "      <td>system and method of feature selection for tex...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>An improved system and method is provided for ...</td>\n",
       "      <td>method feature selection text classification s...</td>\n",
       "      <td>system method feature selection text classific...</td>\n",
       "      <td>improved system method provided feature select...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14304</th>\n",
       "      <td>system and method for performing set operation...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Techniques are provided for improving the spee...</td>\n",
       "      <td>method perform set operation define sketch acc...</td>\n",
       "      <td>system method performing set operations define...</td>\n",
       "      <td>techniques provided improving speed accuracy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14305</th>\n",
       "      <td>a constant-factor approximation algorithm for ...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Co-clustering is the simultaneous partitioning...</td>\n",
       "      <td>constant factor approximation algorithm cluster</td>\n",
       "      <td>constantfactor approximation algorithm coclust</td>\n",
       "      <td>coclustering simultaneous partitioning rows co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14306</th>\n",
       "      <td>method and system for fast similarity computat...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Method, system, and programs for computing sim...</td>\n",
       "      <td>method fast similarity computation high dimens...</td>\n",
       "      <td>method system fast similarity computation high...</td>\n",
       "      <td>method system programs computing similarity in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14307</th>\n",
       "      <td>a framework for estimating stream expression c...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Given $ m $ distributed data streams $ A_1,dot...</td>\n",
       "      <td>framework estimate stream expression cardinali...</td>\n",
       "      <td>framework estimating stream expression cardin</td>\n",
       "      <td>given distributed data streams 1 dots consider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14308</th>\n",
       "      <td>approximate modularity</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>A set function on a ground set of size n is ap...</td>\n",
       "      <td>approximate modularity</td>\n",
       "      <td>approximate modular</td>\n",
       "      <td>set function ground set size n approximately m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14309</th>\n",
       "      <td>tableseer: automatic table metadata extraction...</td>\n",
       "      <td>c. lee giles</td>\n",
       "      <td>Tables are ubiquitous in digital libraries. In...</td>\n",
       "      <td>tableseer automatic table metadata extraction ...</td>\n",
       "      <td>tableseer automatic table metadata extraction ...</td>\n",
       "      <td>tables ubiquitous digital libraries scientific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14310</th>\n",
       "      <td>algorithm for storyboarding in display adverti...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Methods and system for optimally allocating ad...</td>\n",
       "      <td>algorithm storyboarding display advertise</td>\n",
       "      <td>algorithm storyboarding display advertis</td>\n",
       "      <td>methods system optimally allocating ad space a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14311</th>\n",
       "      <td>method and apparatus for identifying if two we...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>A method and apparatus are provided for identi...</td>\n",
       "      <td>method apparatus identify website</td>\n",
       "      <td>method apparatus identifying two websites coown</td>\n",
       "      <td>method apparatus provided identifying two webs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14312</th>\n",
       "      <td>mail compression scheme with individual messag...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Embodiments of the present inversion relate to...</td>\n",
       "      <td>mail compression scheme individual message dec...</td>\n",
       "      <td>mail compression scheme individual message dec...</td>\n",
       "      <td>embodiments present inversion relate twopass c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14313</th>\n",
       "      <td>apparatus and methods for classifying senders ...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>In accordance with one aspect, methods and app...</td>\n",
       "      <td>apparatus method classify sender unsolicited b...</td>\n",
       "      <td>apparatus methods classifying senders unsolici...</td>\n",
       "      <td>accordance one aspect methods apparatus facili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14314</th>\n",
       "      <td>multi-step captcha with serial time-consuming ...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>A system and method for implementing a multi-s...</td>\n",
       "      <td>multi step captcha serial time consume decrypt...</td>\n",
       "      <td>multistep captcha serial timeconsuming decrypt...</td>\n",
       "      <td>system method implementing multistep challenge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14315</th>\n",
       "      <td>on reconstructing a hidden permutation</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>The Mallows model is a classical model for gen...</td>\n",
       "      <td>reconstruct hide permutation</td>\n",
       "      <td>reconstructing hidden permut</td>\n",
       "      <td>mallows model classical model generating noisy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14316</th>\n",
       "      <td>hierarchical structure entropy measurement met...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Methods and apparatuses are provided for acces...</td>\n",
       "      <td>hierarchical structure entropy measurement method</td>\n",
       "      <td>hierarchical structure entropy measurement met...</td>\n",
       "      <td>methods apparatuses provided accessing taxonom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14317</th>\n",
       "      <td>online story scheduling in web advertising</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>We study an online job scheduling problem moti...</td>\n",
       "      <td>online story schedule web advertise</td>\n",
       "      <td>online story scheduling web advertis</td>\n",
       "      <td>study online job scheduling problem motivated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14318</th>\n",
       "      <td>on learning mixture models for permutations</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>In this paper we consider the problem of learn...</td>\n",
       "      <td>learn mixture model permutation</td>\n",
       "      <td>learning mixture models permut</td>\n",
       "      <td>paper consider problem learning mixture permut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14319</th>\n",
       "      <td>captchas that include overlapped characters, p...</td>\n",
       "      <td>anirban dasgupta</td>\n",
       "      <td>Techniques are described herein for generating...</td>\n",
       "      <td>captchas include overlap character projection ...</td>\n",
       "      <td>captchas include overlapped characters project...</td>\n",
       "      <td>techniques described herein generating captcha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14320</th>\n",
       "      <td>who gets acknowledged: measuring scientific co...</td>\n",
       "      <td>c. lee giles</td>\n",
       "      <td>Acknowledgments in research publications, like...</td>\n",
       "      <td>acknowledge measure scientific contribution au...</td>\n",
       "      <td>gets acknowledged measuring scientific contrib...</td>\n",
       "      <td>acknowledgments research publications like cit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14321 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Judul          Reviewer  \\\n",
       "0            impact of spam exposure on user engagement.  anirban dasgupta   \n",
       "1      a real time algorithm for detection of spectac...  anirban dasgupta   \n",
       "2      clustering cookies for identifying unique mobi...  anirban dasgupta   \n",
       "3      video & eog based investigation of pure saccad...  anirban dasgupta   \n",
       "4      spam or ham?: characterizing and detecting fra...  anirban dasgupta   \n",
       "5        overcoming browser cookie churn with clustering  anirban dasgupta   \n",
       "6                         on sampling nodes in a network  anirban dasgupta   \n",
       "7      analysis of training parameters for classifier...  anirban dasgupta   \n",
       "8      an on-board vision based system for drowsiness...  anirban dasgupta   \n",
       "9      disambiguating authors in academic publication...      c. lee giles   \n",
       "10     automated alertness and emotion detection for ...  anirban dasgupta   \n",
       "11          system and method for counting network users  anirban dasgupta   \n",
       "12     constructing image captchas utilizing private ...  anirban dasgupta   \n",
       "13     vote calibration in community question-answeri...  anirban dasgupta   \n",
       "14         spectral clustering with limited independence  anirban dasgupta   \n",
       "15                     quantified computation tree logic  anirban dasgupta   \n",
       "16                     variable latent semantic indexing  anirban dasgupta   \n",
       "17     enhanced email spam filtering through combinin...  anirban dasgupta   \n",
       "18     sparse and lopsided set disjointness via infor...  anirban dasgupta   \n",
       "19     systems and methods of universal resource loca...  anirban dasgupta   \n",
       "20     automatic identification of informative sectio...      c. lee giles   \n",
       "21           optimal hashing schemes for entity matching  anirban dasgupta   \n",
       "22     selecting diverse features via spectral regula...  anirban dasgupta   \n",
       "23                playful incentive for labeling content  anirban dasgupta   \n",
       "24     summarization through submodularity and disper...  anirban dasgupta   \n",
       "25                                       social sampling  anirban dasgupta   \n",
       "26         spectral clustering by recursive partitioning  anirban dasgupta   \n",
       "27                      on estimating the average degree  anirban dasgupta   \n",
       "28     collaborative email-spam filtering with the ha...  anirban dasgupta   \n",
       "29     a vision-based system for monitoring the loss ...  anirban dasgupta   \n",
       "...                                                  ...               ...   \n",
       "14291  random projections in gravitational wave searc...  anirban dasgupta   \n",
       "14292  an evaluation of multi-probe locality sensitiv...  anirban dasgupta   \n",
       "14293  task-specific representation learning for web-...  anirban dasgupta   \n",
       "14294  a portable personality recognizer based on aff...  anirban dasgupta   \n",
       "14295  diminishing communities in large social and in...  anirban dasgupta   \n",
       "14296  collaborative spam filtering with the hashing ...  anirban dasgupta   \n",
       "14297  a review on extension of lagrangian-hamiltonia...  anirban dasgupta   \n",
       "14298                 probabilistic user behavior models      c. lee giles   \n",
       "14299  aggregating information from the crowd and the...  anirban dasgupta   \n",
       "14300  supplementary material: large-scale community ...  anirban dasgupta   \n",
       "14301                               user trustworthiness  anirban dasgupta   \n",
       "14302                 marketplace for captcha developers  anirban dasgupta   \n",
       "14303  system and method of feature selection for tex...  anirban dasgupta   \n",
       "14304  system and method for performing set operation...  anirban dasgupta   \n",
       "14305  a constant-factor approximation algorithm for ...  anirban dasgupta   \n",
       "14306  method and system for fast similarity computat...  anirban dasgupta   \n",
       "14307  a framework for estimating stream expression c...  anirban dasgupta   \n",
       "14308                             approximate modularity  anirban dasgupta   \n",
       "14309  tableseer: automatic table metadata extraction...      c. lee giles   \n",
       "14310  algorithm for storyboarding in display adverti...  anirban dasgupta   \n",
       "14311  method and apparatus for identifying if two we...  anirban dasgupta   \n",
       "14312  mail compression scheme with individual messag...  anirban dasgupta   \n",
       "14313  apparatus and methods for classifying senders ...  anirban dasgupta   \n",
       "14314  multi-step captcha with serial time-consuming ...  anirban dasgupta   \n",
       "14315             on reconstructing a hidden permutation  anirban dasgupta   \n",
       "14316  hierarchical structure entropy measurement met...  anirban dasgupta   \n",
       "14317         online story scheduling in web advertising  anirban dasgupta   \n",
       "14318        on learning mixture models for permutations  anirban dasgupta   \n",
       "14319  captchas that include overlapped characters, p...  anirban dasgupta   \n",
       "14320  who gets acknowledged: measuring scientific co...      c. lee giles   \n",
       "\n",
       "                                                 Abstrak  \\\n",
       "0      In this paper we quantify the effect of unsoli...   \n",
       "1      Eye detection plays an important role in many ...   \n",
       "2      Embodiments are directed towards clustering co...   \n",
       "3      Human Computer Interaction (HCI) is the method...   \n",
       "4      Web mail providers rely on users to\\\" vote\\\" t...   \n",
       "5      Many large Internet websites are accessed by u...   \n",
       "6      Random walk is an important tool in many graph...   \n",
       "7      This paper analyzes the performance of the Haa...   \n",
       "8      This paper proposes a system for on-board moni...   \n",
       "9      Users of digital libraries usually want to kno...   \n",
       "10     In the context of education technology, empath...   \n",
       "11     Embodiments presented herein provide methods, ...   \n",
       "12     An image CAPTCHA having one or more images, a ...   \n",
       "13     User votes are important signals in community ...   \n",
       "14     This paper considers the well-studied problem ...   \n",
       "15     Computation Tree Logic (CTL) is one of the mos...   \n",
       "16     Latent Semantic Indexing is a classical method...   \n",
       "17     Over the last decade Email Spam has evolved fr...   \n",
       "18     We study two natural variations of the set dis...   \n",
       "19     Disclosed herein are method, systems and archi...   \n",
       "20     Web pages-especially dynamically generated one...   \n",
       "21     In this paper, we consider the problem of devi...   \n",
       "22     We study the problem of diverse feature select...   \n",
       "23     Embodiments are directed towards employing a p...   \n",
       "24     We propose a new optimization framework for su...   \n",
       "25     How people assess their social environments pl...   \n",
       "26     In this paper, we analyze the second eigenvect...   \n",
       "27     Networks are characterized by nodes and edges....   \n",
       "28     This paper delves into a recently proposed tec...   \n",
       "29     Onboard monitoring of the alertness level of a...   \n",
       "...                                                  ...   \n",
       "14291  Random projection (RP) is a powerful dimension...   \n",
       "14292  Many modern applications of AI such as web sea...   \n",
       "14293  Named entity disambiguation (NED) is a central...   \n",
       "14294  In this paper, we introduce a system named Por...   \n",
       "14295  A large body of work has been devoted to ident...   \n",
       "14296  User feedback is vital to the quality of the c...   \n",
       "14297  This paper presents a brief review on Lagrangi...   \n",
       "14298  We present a mixture model based approach for ...   \n",
       "14299  In social systems, information often exists in...   \n",
       "14300  A central question for our conclusions in the ...   \n",
       "14301  In order to improve RBAC, first we define trus...   \n",
       "14302  Techniques are described herein for providing ...   \n",
       "14303  An improved system and method is provided for ...   \n",
       "14304  Techniques are provided for improving the spee...   \n",
       "14305  Co-clustering is the simultaneous partitioning...   \n",
       "14306  Method, system, and programs for computing sim...   \n",
       "14307  Given $ m $ distributed data streams $ A_1,dot...   \n",
       "14308  A set function on a ground set of size n is ap...   \n",
       "14309  Tables are ubiquitous in digital libraries. In...   \n",
       "14310  Methods and system for optimally allocating ad...   \n",
       "14311  A method and apparatus are provided for identi...   \n",
       "14312  Embodiments of the present inversion relate to...   \n",
       "14313  In accordance with one aspect, methods and app...   \n",
       "14314  A system and method for implementing a multi-s...   \n",
       "14315  The Mallows model is a classical model for gen...   \n",
       "14316  Methods and apparatuses are provided for acces...   \n",
       "14317  We study an online job scheduling problem moti...   \n",
       "14318  In this paper we consider the problem of learn...   \n",
       "14319  Techniques are described herein for generating...   \n",
       "14320  Acknowledgments in research publications, like...   \n",
       "\n",
       "                                            preprocessed  \\\n",
       "0                   impact spam exposure user engagement   \n",
       "1      real time algorithm detection spectacle lead e...   \n",
       "2            cluster cooky identify unique mobile device   \n",
       "3      video    eog base investigation pure saccade h...   \n",
       "4      spam    characterize detect fraudulent spam re...   \n",
       "5                  overcome browser cookie churn cluster   \n",
       "6                                    sample node network   \n",
       "7      analysis train parameter classifier base featu...   \n",
       "8      board vision base drowsiness detection automot...   \n",
       "9      disambiguate author academic publication rando...   \n",
       "10     automate alertness emotion detection empathic ...   \n",
       "11                             method count network user   \n",
       "12        construct image captchas utilize private image   \n",
       "13            vote calibration community question answer   \n",
       "14                   spectral cluster limit independence   \n",
       "15                       quantify computation tree logic   \n",
       "16                              variable latent semantic   \n",
       "17     enhance email spam filter combine similarity g...   \n",
       "18               sparse lopsided set disjointness theory   \n",
       "19       method universal resource locator normalization   \n",
       "20              automatic identification informative web   \n",
       "21                      optimal hash scheme entity match   \n",
       "22        select diverse feature spectral regularization   \n",
       "23                       playful incentive label content   \n",
       "24                summarization submodularity dispersion   \n",
       "25                                         social sample   \n",
       "26                  spectral cluster recursive partition   \n",
       "27                               estimate average degree   \n",
       "28            collaborative email spam filter hash trick   \n",
       "29     vision base monitor loss attention automotive ...   \n",
       "...                                                  ...   \n",
       "14291  random projection gravitational wave search co...   \n",
       "14292  evaluation multi probe locality sensitive hash...   \n",
       "14293  task specific representation learn web scale e...   \n",
       "14294  portable personality recognizer base affective...   \n",
       "14295            diminish community large social network   \n",
       "14296               collaborative spam filter hash trick   \n",
       "14297   review extension lagrangian hamiltonian mechanic   \n",
       "14298                  probabilistic user behavior model   \n",
       "14299                            aggregate crowd network   \n",
       "14300  supplementary material large scale community s...   \n",
       "14301                               user trustworthiness   \n",
       "14302                      marketplace captcha developer   \n",
       "14303  method feature selection text classification s...   \n",
       "14304  method perform set operation define sketch acc...   \n",
       "14305    constant factor approximation algorithm cluster   \n",
       "14306  method fast similarity computation high dimens...   \n",
       "14307  framework estimate stream expression cardinali...   \n",
       "14308                             approximate modularity   \n",
       "14309  tableseer automatic table metadata extraction ...   \n",
       "14310          algorithm storyboarding display advertise   \n",
       "14311                  method apparatus identify website   \n",
       "14312  mail compression scheme individual message dec...   \n",
       "14313  apparatus method classify sender unsolicited b...   \n",
       "14314  multi step captcha serial time consume decrypt...   \n",
       "14315                       reconstruct hide permutation   \n",
       "14316  hierarchical structure entropy measurement method   \n",
       "14317                online story schedule web advertise   \n",
       "14318                    learn mixture model permutation   \n",
       "14319  captchas include overlap character projection ...   \n",
       "14320  acknowledge measure scientific contribution au...   \n",
       "\n",
       "                                      preprocessed_judul  \\\n",
       "0                        impact spam exposure user engag   \n",
       "1      real time algorithm detection spectacles leadi...   \n",
       "2      clustering cookies identifying unique mobile d...   \n",
       "3      video eog based investigation pure saccades hu...   \n",
       "4      spam ham characterizing detecting fraudulent s...   \n",
       "5                  overcoming browser cookie churn clust   \n",
       "6                                 sampling nodes network   \n",
       "7      analysis training parameters classifiers based...   \n",
       "8      onboard vision based system drowsiness detecti...   \n",
       "9      disambiguating authors academic publications u...   \n",
       "10     automated alertness emotion detection empathic...   \n",
       "11                     system method counting network us   \n",
       "12     constructing image captchas utilizing private ...   \n",
       "13     vote calibration community questionanswering s...   \n",
       "14                  spectral clustering limited independ   \n",
       "15                       quantified computation tree log   \n",
       "16                        variable latent semantic index   \n",
       "17     enhanced email spam filtering combining simila...   \n",
       "18     sparse lopsided set disjointness via informati...   \n",
       "19       systems methods universal resource locator norm   \n",
       "20     automatic identification informative sections ...   \n",
       "21                  optimal hashing schemes entity match   \n",
       "22       selecting diverse features via spectral regular   \n",
       "23                       playful incentive labeling cont   \n",
       "24                   summarization submodularity dispers   \n",
       "25                                          social sampl   \n",
       "26                  spectral clustering recursive partit   \n",
       "27                              estimating average degre   \n",
       "28       collaborative emailspam filtering hashing trick   \n",
       "29     visionbased system monitoring loss attention a...   \n",
       "...                                                  ...   \n",
       "14291  random projections gravitational wave searches...   \n",
       "14292  evaluation multiprobe locality sensitive hashi...   \n",
       "14293  taskspecific representation learning webscale ...   \n",
       "14294  portable personality recognizer based affectiv...   \n",
       "14295  diminishing communities large social informati...   \n",
       "14296         collaborative spam filtering hashing trick   \n",
       "14297      review extension lagrangianhamiltonian mechan   \n",
       "14298                  probabilistic user behavior model   \n",
       "14299              aggregating information crowd network   \n",
       "14300  supplementary material largescale community st...   \n",
       "14301                                   user trustworthi   \n",
       "14302                        marketplace captcha develop   \n",
       "14303  system method feature selection text classific...   \n",
       "14304  system method performing set operations define...   \n",
       "14305     constantfactor approximation algorithm coclust   \n",
       "14306  method system fast similarity computation high...   \n",
       "14307      framework estimating stream expression cardin   \n",
       "14308                                approximate modular   \n",
       "14309  tableseer automatic table metadata extraction ...   \n",
       "14310           algorithm storyboarding display advertis   \n",
       "14311    method apparatus identifying two websites coown   \n",
       "14312  mail compression scheme individual message dec...   \n",
       "14313  apparatus methods classifying senders unsolici...   \n",
       "14314  multistep captcha serial timeconsuming decrypt...   \n",
       "14315                       reconstructing hidden permut   \n",
       "14316  hierarchical structure entropy measurement met...   \n",
       "14317               online story scheduling web advertis   \n",
       "14318                     learning mixture models permut   \n",
       "14319  captchas include overlapped characters project...   \n",
       "14320  gets acknowledged measuring scientific contrib...   \n",
       "\n",
       "                                    preprocessed_abstrak  \n",
       "0      paper quantify effect unsolicited emails spam ...  \n",
       "1      eye detection plays important role many intell...  \n",
       "2      embodiments directed towards clustering cookie...  \n",
       "3      human computer interaction hci methodology com...  \n",
       "4      web mail providers rely users vote quickly col...  \n",
       "5      many large internet websites accessed users an...  \n",
       "6      random walk important tool many graph mining a...  \n",
       "7      paper analyzes performance haarlike feature ba...  \n",
       "8      paper proposes system onboard monitoring loss ...  \n",
       "9      users digital libraries usually want know exac...  \n",
       "10     context education technology empathic interact...  \n",
       "11     embodiments presented herein provide methods s...  \n",
       "12     image captcha one images challenge correct ans...  \n",
       "13     user votes important signals community questio...  \n",
       "14     paper considers wellstudied problem clustering...  \n",
       "15     computation tree logic ctl one syntactically e...  \n",
       "16     latent semantic indexing classical method prod...  \n",
       "17     last decade email spam evolved irritant users ...  \n",
       "18     study two natural variations set disjointness ...  \n",
       "19     disclosed herein method systems architectures ...  \n",
       "20     web pagesespecially dynamically generated ones...  \n",
       "21     paper consider problem devising blocking schem...  \n",
       "22     study problem diverse feature selection linear...  \n",
       "23     embodiments directed towards employing playful...  \n",
       "24     propose new optimization framework summarizati...  \n",
       "25     people assess social environments plays centra...  \n",
       "26     paper analyze second eigenvector technique spe...  \n",
       "27     networks characterized nodes edges spate recen...  \n",
       "28     paper delves recently proposed technique colla...  \n",
       "29     onboard monitoring alertness level automotive ...  \n",
       "...                                                  ...  \n",
       "14291  random projection rp powerful dimension reduct...  \n",
       "14292  many modern applications ai web search mobile ...  \n",
       "14293  named entity disambiguation ned central proble...  \n",
       "14294  paper introduce system named portable personal...  \n",
       "14295  large body work devoted identifying communitie...  \n",
       "14296  user feedback vital quality collaborative spam...  \n",
       "14297  paper presents brief review lagrangianhamilton...  \n",
       "14298  present mixture model based approach learning ...  \n",
       "14299  social systems information often exists disper...  \n",
       "14300  central question conclusions main text extent ...  \n",
       "14301  order improve rbac first define trust trust wo...  \n",
       "14302  techniques described herein providing marketpl...  \n",
       "14303  improved system method provided feature select...  \n",
       "14304  techniques provided improving speed accuracy a...  \n",
       "14305  coclustering simultaneous partitioning rows co...  \n",
       "14306  method system programs computing similarity in...  \n",
       "14307  given distributed data streams 1 dots consider...  \n",
       "14308  set function ground set size n approximately m...  \n",
       "14309  tables ubiquitous digital libraries scientific...  \n",
       "14310  methods system optimally allocating ad space a...  \n",
       "14311  method apparatus provided identifying two webs...  \n",
       "14312  embodiments present inversion relate twopass c...  \n",
       "14313  accordance one aspect methods apparatus facili...  \n",
       "14314  system method implementing multistep challenge...  \n",
       "14315  mallows model classical model generating noisy...  \n",
       "14316  methods apparatuses provided accessing taxonom...  \n",
       "14317  study online job scheduling problem motivated ...  \n",
       "14318  paper consider problem learning mixture permut...  \n",
       "14319  techniques described herein generating captcha...  \n",
       "14320  acknowledgments research publications like cit...  \n",
       "\n",
       "[14321 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambildata = pd.read_excel(\"preprocessed-dataset.xlsx\", sep=',')\n",
    "ambildata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LoadDocuments(dPath=None,types=None, file = None): # types = ['pdf','doc','docx','txt','bz2']\n",
    "    Files, Docs = [], []\n",
    "    if types:\n",
    "        for tipe in types:\n",
    "            Files += crawlFiles(dPath,tipe)\n",
    "    if file:\n",
    "        Files = [file]\n",
    "    if not types and not file: # get all files regardless of their extensions\n",
    "        Files += crawlFiles(dPath)\n",
    "    for f in Files:\n",
    "        if f[-3:].lower()=='pdf':\n",
    "            try:\n",
    "                Docs.append(PDF(f).string)\n",
    "            except:\n",
    "                print('error reading{0}'.format(f))\n",
    "        elif f[-3:].lower() in ['txt', 'dic','py', 'ipynb']:\n",
    "            try:\n",
    "                df=open(f,\"r\",encoding=\"utf-8\", errors='replace')\n",
    "                Docs.append(df.readlines());df.close()\n",
    "            except:\n",
    "                print('error reading{0}'.format(f))\n",
    "        elif f[-3:].lower()=='bz2':\n",
    "            try:\n",
    "                Docs.append(readBz2(f))\n",
    "            except:\n",
    "                print('error reading{0}'.format(f))\n",
    "        elif f[-4:].lower()=='docx':\n",
    "            try:\n",
    "                Docs.append(docx2txt.process(f))\n",
    "            except:\n",
    "                print('error reading{0}'.format(f))\n",
    "        elif f[-3:].lower()=='csv':\n",
    "            Docs.append(pd.read_csv(f))\n",
    "        else:\n",
    "            print('Unsupported format {0}'.format(f))\n",
    "    if file:\n",
    "        Docs = Docs[0]\n",
    "    return Docs, Files\n",
    "def LoadStopWords(lang='en'):\n",
    "    L = lang.lower().strip()\n",
    "    if L == 'en' or L == 'english' or L == 'inggris':\n",
    "        from spacy.lang.en import English as lemmatizer\n",
    "        #lemmatizer = spacy.lang.en.English\n",
    "        lemmatizer = lemmatizer()\n",
    "        #lemmatizer = spacy.load('en')\n",
    "        stops =  set([t.strip() for t in LoadDocuments(file = 'data/stopwords_eng.txt')[0]])\n",
    "    elif L == 'id' or L == 'indonesia' or L=='indonesian':\n",
    "        from spacy.lang.id import Indonesian\n",
    "        #lemmatizer = spacy.lang.id.Indonesian\n",
    "        lemmatizer = Indonesian()\n",
    "        stops = set([t.strip() for t in LoadDocuments(file = 'data/stopwords_id.txt')[0]])\n",
    "    else:\n",
    "        print('Warning, language not recognized. Empty StopWords Given')\n",
    "        stops = set(); lemmatizer = None\n",
    "    return stops, lemmatizer\n",
    "def cleanText(T, fix={}, lemma=None, stops = set(), symbols_remove = True, min_charLen = 2, fixTag= True):\n",
    "    # lang & stopS only 2 options : 'en' atau 'id'\n",
    "    # symbols ASCII atau alnum\n",
    "    pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    t = re.sub(pattern,' ',T) #remove urls if any\n",
    "    pattern = re.compile(r'ftp[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    t = re.sub(pattern,' ',t) #remove urls if any\n",
    "    t = unescape(t) # html entities fix\n",
    "    if fixTag:\n",
    "        t = fixTags(t) # fix abcDef\n",
    "    t = t.lower().strip() # lowercase\n",
    "    t = unidecode(t)\n",
    "    t = ''.join(''.join(s)[:2] for _, s in itertools.groupby(t)) # remove repetition\n",
    "    t = t.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    t = sent_tokenize(t) # sentence segmentation. String to list\n",
    "    for i, K in enumerate(t):\n",
    "        if symbols_remove:\n",
    "            K = re.sub(r'[^.,_a-zA-Z0-9 \\.]',' ',K)\n",
    "        if lemma:\n",
    "            listKata = lemma(K)\n",
    "        else:\n",
    "            listKata = TextBlob(K).words\n",
    "        cleanList = []\n",
    "        for token in listKata:\n",
    "            if lemma:\n",
    "                if str(token.text) in fix.keys():\n",
    "                    token = fix[str(token.text)]\n",
    "                try:\n",
    "                    token = token.lemma_\n",
    "                except:\n",
    "                    token = lemma(token)[0].lemma_\n",
    "            else:\n",
    "                if str(token) in fix.keys():\n",
    "                    token = fix[str(token)]\n",
    "            if stops:\n",
    "                if len(token)>=min_charLen and token not in stops:\n",
    "                    cleanList.append(token)\n",
    "            else:\n",
    "                if len(token)>=min_charLen:\n",
    "                    cleanList.append(token)\n",
    "        t[i] = ' '.join(cleanList)\n",
    "    return ' '.join(t) # Return kalimat lagi\n",
    "def fixTags(t):\n",
    "    getHashtags = re.compile(r\"#(\\w+)\")\n",
    "    pisahtags = re.compile(r'[A-Z][^A-Z]*')\n",
    "    tagS = re.findall(getHashtags, t)\n",
    "    for tag in tagS:\n",
    "        if len(tag)>0:\n",
    "            tg = tag[0].upper()+tag[1:]\n",
    "            proper_words = []\n",
    "            if adaAngka(tg):\n",
    "                tag2 = re.split('(\\d+)',tg)\n",
    "                tag2 = [w for w in tag2 if len(w)>0]\n",
    "                for w in tag2:\n",
    "                    try:\n",
    "                        _ = int(w) # error if w not a number\n",
    "                        proper_words.append(w)\n",
    "                    except:\n",
    "                        w = w[0].upper()+w[1:]\n",
    "                        proper_words = proper_words+re.findall(pisahtags, w)\n",
    "            else:\n",
    "                proper_words = re.findall(pisahtags, tg)\n",
    "            proper_words = ' '.join(proper_words)\n",
    "            t = t.replace('#'+tag, proper_words)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ambil= ambildata['Judul']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyaknya produk =  4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6398d6830d264ebf8425611e23ae563e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contoh deskripsi produk pertama =  0    sistem learning berbasis model motivasi komunitas\n",
      "1                  strategi kelola situs learning ajar\n",
      "2           pilih sistem learning berbasis open source\n",
      "3            kembang sistem learning multimedia gratis\n",
      "Name: Judul, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re, networkx as nx, matplotlib.pyplot as plt, operator, numpy as np,community, os, docx2txt, csv#, spacy\n",
    "from unidecode import unidecode\n",
    "import json, pandas as pd, itertools, nltk, time\n",
    "from nltk import sent_tokenize\n",
    "from html import unescape\n",
    "\n",
    "\n",
    "list_preprocessing_pada_judul_penelitian = []\n",
    "print('Banyaknya produk = ', len(ambildata))\n",
    "\n",
    "stops, lemmatizer = LoadStopWords(lang='id')\n",
    "for i,d in tqdm(enumerate(ambil)):\n",
    "    ambil[i] = cleanText(d, lemma=lemmatizer, stops = stops, symbols_remove = True, min_charLen = 2)\n",
    "    list_preprocessing_pada_judul_penelitian.append(ambil[i])\n",
    "print('Contoh deskripsi produk pertama = ', ambil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Judul</th>\n",
       "      <th>Lematizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sistem learning berbasis model motivasi komunitas</td>\n",
       "      <td>sistem learning berbasis model motivasi komunitas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>strategi kelola situs learning ajar</td>\n",
       "      <td>strategi kelola situs learning ajar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pilih sistem learning berbasis open source</td>\n",
       "      <td>pilih sistem learning berbasis open source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>kembang sistem learning multimedia gratis</td>\n",
       "      <td>kembang sistem learning multimedia gratis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Judul  \\\n",
       "0           1  sistem learning berbasis model motivasi komunitas   \n",
       "1           2                strategi kelola situs learning ajar   \n",
       "2           3         pilih sistem learning berbasis open source   \n",
       "3           4          kembang sistem learning multimedia gratis   \n",
       "\n",
       "                                           Lematizer  \n",
       "0  sistem learning berbasis model motivasi komunitas  \n",
       "1                strategi kelola situs learning ajar  \n",
       "2         pilih sistem learning berbasis open source  \n",
       "3          kembang sistem learning multimedia gratis  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"test.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sistem learning berbasis model motivasi komunitas',\n",
       "       'strategi kelola situs learning ajar',\n",
       "       'pilih sistem learning berbasis open source',\n",
       "       'kembang sistem learning multimedia gratis'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[\"Lematizer\"].values\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sistem  -  1.2876820724517808\n",
      "learning  -  1.0\n",
      "berbasis  -  1.6931471805599454\n",
      "model  -  2.386294361119891\n",
      "motivasi  -  2.386294361119891\n",
      "komunitas  -  2.386294361119891\n",
      "learning  -  1.0\n",
      "strategi  -  0.0\n",
      "kelola  -  0.0\n",
      "situs  -  0.0\n",
      "ajar  -  0.0\n",
      "sistem  -  1.2876820724517808\n",
      "learning  -  1.0\n",
      "berbasis  -  1.6931471805599454\n",
      "pilih  -  0.0\n",
      "open  -  0.0\n",
      "source  -  0.0\n",
      "sistem  -  1.2876820724517808\n",
      "learning  -  1.0\n",
      "kembang  -  0.0\n",
      "multimedia  -  0.0\n",
      "gratis  -  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(smooth_idf=False, norm=None)\n",
    "tfidf = vectorizer.fit_transform(data)\n",
    "words = vectorizer.get_feature_names()\n",
    "similarity_matrix = cosine_similarity(tfidf)\n",
    "for col in tfidf.nonzero()[1]:\n",
    "    print (words[col], ' - ', tfidf[0, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.386294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.386294</td>\n",
       "      <td>2.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.386294</td>\n",
       "      <td>2.386294</td>\n",
       "      <td>1.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.386294</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5    6         7   \\\n",
       "0  0.000000  1.693147  0.000000  0.000000  0.000000  2.386294  1.0  2.386294   \n",
       "1  2.386294  0.000000  0.000000  2.386294  0.000000  0.000000  1.0  0.000000   \n",
       "2  0.000000  1.693147  0.000000  0.000000  0.000000  0.000000  1.0  0.000000   \n",
       "3  0.000000  0.000000  2.386294  0.000000  2.386294  0.000000  1.0  0.000000   \n",
       "\n",
       "         8         9         10        11        12        13        14  \\\n",
       "0  2.386294  0.000000  0.000000  0.000000  1.287682  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  2.386294  0.000000   \n",
       "2  0.000000  0.000000  2.386294  2.386294  1.287682  0.000000  2.386294   \n",
       "3  0.000000  2.386294  0.000000  0.000000  1.287682  0.000000  0.000000   \n",
       "\n",
       "         15  \n",
       "0  0.000000  \n",
       "1  2.386294  \n",
       "2  0.000000  \n",
       "3  0.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform(data)\n",
    "array = tfidf_matrix.todense()\n",
    "df = pd.DataFrame(array)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 16)\n",
      "[[0.         1.69314718 0.         0.         0.         2.38629436\n",
      "  1.         2.38629436 2.38629436 0.         0.         0.\n",
      "  1.28768207 0.         0.         0.        ]\n",
      " [2.38629436 0.         0.         2.38629436 0.         0.\n",
      "  1.         0.         0.         0.         0.         0.\n",
      "  0.         2.38629436 0.         2.38629436]\n",
      " [0.         1.69314718 0.         0.         0.         0.\n",
      "  1.         0.         0.         0.         2.38629436 2.38629436\n",
      "  1.28768207 0.         2.38629436 0.        ]\n",
      " [0.         0.         2.38629436 0.         2.38629436 0.\n",
      "  1.         0.         0.         2.38629436 0.         0.\n",
      "  1.28768207 0.         0.         0.        ]]\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.shape)\n",
    "print(tfidf.toarray())\n",
    "print(tfidf.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukuran-ukuran matriks =  (4, 2) (2,) (2, 16)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import linalg\n",
    "\n",
    "U,S,V = linalg.svds(tfidf,k=2)\n",
    "print(\"ukuran-ukuran matriks = \",U.shape, S.shape, V.shape)\n",
    "print(type(U))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package scipy.sparse.linalg in scipy.sparse:\n",
      "\n",
      "NAME\n",
      "    scipy.sparse.linalg\n",
      "\n",
      "DESCRIPTION\n",
      "    ==================================================\n",
      "    Sparse linear algebra (:mod:`scipy.sparse.linalg`)\n",
      "    ==================================================\n",
      "    \n",
      "    .. currentmodule:: scipy.sparse.linalg\n",
      "    \n",
      "    Abstract linear operators\n",
      "    -------------------------\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       LinearOperator -- abstract representation of a linear operator\n",
      "       aslinearoperator -- convert an object to an abstract linear operator\n",
      "    \n",
      "    Matrix Operations\n",
      "    -----------------\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       inv -- compute the sparse matrix inverse\n",
      "       expm -- compute the sparse matrix exponential\n",
      "       expm_multiply -- compute the product of a matrix exponential and a matrix\n",
      "    \n",
      "    Matrix norms\n",
      "    ------------\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       norm -- Norm of a sparse matrix\n",
      "       onenormest -- Estimate the 1-norm of a sparse matrix\n",
      "    \n",
      "    Solving linear problems\n",
      "    -----------------------\n",
      "    \n",
      "    Direct methods for linear equation systems:\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       spsolve -- Solve the sparse linear system Ax=b\n",
      "       spsolve_triangular -- Solve the sparse linear system Ax=b for a triangular matrix\n",
      "       factorized -- Pre-factorize matrix to a function solving a linear system\n",
      "       MatrixRankWarning -- Warning on exactly singular matrices\n",
      "       use_solver -- Select direct solver to use\n",
      "    \n",
      "    Iterative methods for linear equation systems:\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       bicg -- Use BIConjugate Gradient iteration to solve A x = b\n",
      "       bicgstab -- Use BIConjugate Gradient STABilized iteration to solve A x = b\n",
      "       cg -- Use Conjugate Gradient iteration to solve A x = b\n",
      "       cgs -- Use Conjugate Gradient Squared iteration to solve A x = b\n",
      "       gmres -- Use Generalized Minimal RESidual iteration to solve A x = b\n",
      "       lgmres -- Solve a matrix equation using the LGMRES algorithm\n",
      "       minres -- Use MINimum RESidual iteration to solve Ax = b\n",
      "       qmr -- Use Quasi-Minimal Residual iteration to solve A x = b\n",
      "       gcrotmk -- Solve a matrix equation using the GCROT(m,k) algorithm\n",
      "    \n",
      "    Iterative methods for least-squares problems:\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       lsqr -- Find the least-squares solution to a sparse linear equation system\n",
      "       lsmr -- Find the least-squares solution to a sparse linear equation system\n",
      "    \n",
      "    Matrix factorizations\n",
      "    ---------------------\n",
      "    \n",
      "    Eigenvalue problems:\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       eigs -- Find k eigenvalues and eigenvectors of the square matrix A\n",
      "       eigsh -- Find k eigenvalues and eigenvectors of a symmetric matrix\n",
      "       lobpcg -- Solve symmetric partial eigenproblems with optional preconditioning\n",
      "    \n",
      "    Singular values problems:\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       svds -- Compute k singular values/vectors for a sparse matrix\n",
      "    \n",
      "    Complete or incomplete LU factorizations\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       splu -- Compute a LU decomposition for a sparse matrix\n",
      "       spilu -- Compute an incomplete LU decomposition for a sparse matrix\n",
      "       SuperLU -- Object representing an LU factorization\n",
      "    \n",
      "    Exceptions\n",
      "    ----------\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       ArpackNoConvergence\n",
      "       ArpackError\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _expm_multiply\n",
      "    _norm\n",
      "    _onenormest\n",
      "    dsolve (package)\n",
      "    eigen (package)\n",
      "    interface\n",
      "    isolve (package)\n",
      "    matfuncs\n",
      "    setup\n",
      "    tests (package)\n",
      "\n",
      "SUBMODULES\n",
      "    arpack\n",
      "    iterative\n",
      "    linsolve\n",
      "    utils\n",
      "\n",
      "CLASSES\n",
      "    builtins.RuntimeError(builtins.Exception)\n",
      "        scipy.sparse.linalg.eigen.arpack.arpack.ArpackError\n",
      "            scipy.sparse.linalg.eigen.arpack.arpack.ArpackNoConvergence\n",
      "    builtins.UserWarning(builtins.Warning)\n",
      "        scipy.sparse.linalg.dsolve.linsolve.MatrixRankWarning\n",
      "    builtins.object\n",
      "        builtins.SuperLU\n",
      "        scipy.sparse.linalg.interface.LinearOperator\n",
      "    \n",
      "    class ArpackError(builtins.RuntimeError)\n",
      "     |  ARPACK error\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ArpackError\n",
      "     |      builtins.RuntimeError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, info, infodict={'d': {0: 'Normal exit.', 1: 'Maximum number of iterations taken. All possible eigenvalues of OP has been found. IPARAM(5) returns the number of wanted converged Ritz values.', 2: 'No longer an informational error. Deprecated starting with release 2 of ARPACK.', 3: 'No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ', -1: 'N must be positive.', -2: 'NEV must be positive.', -3: 'NCV-NEV >= 2 and less than or equal to N.', -4: 'The maximum number of Arnoldi update iterations allowed must be greater than zero.', -5: \" WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\", -6: \"BMAT must be one of 'I' or 'G'.\", -7: 'Length of private work array WORKL is not sufficient.', -8: 'Error return from LAPACK eigenvalue calculation;', -9: 'Starting vector is zero.', -10: 'IPARAM(7) must be 1,2,3,4.', -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\", -12: 'IPARAM(1) must be equal to 0 or 1.', -13: \"NEV and WHICH = 'BE' are incompatible.\", -9999: 'Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.'}, 's': {0: 'Normal exit.', 1: 'Maximum number of iterations taken. All possible eigenvalues of OP has been found. IPARAM(5) returns the number of wanted converged Ritz values.', 2: 'No longer an informational error. Deprecated starting with release 2 of ARPACK.', 3: 'No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ', -1: 'N must be positive.', -2: 'NEV must be positive.', -3: 'NCV-NEV >= 2 and less than or equal to N.', -4: 'The maximum number of Arnoldi update iterations allowed must be greater than zero.', -5: \" WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\", -6: \"BMAT must be one of 'I' or 'G'.\", -7: 'Length of private work array WORKL is not sufficient.', -8: 'Error return from LAPACK eigenvalue calculation;', -9: 'Starting vector is zero.', -10: 'IPARAM(7) must be 1,2,3,4.', -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\", -12: 'IPARAM(1) must be equal to 0 or 1.', -13: \"NEV and WHICH = 'BE' are incompatible.\", -9999: 'Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.'}, 'z': {0: 'Normal exit.', 1: 'Maximum number of iterations taken. All possible eigenvalues of OP has been found. IPARAM(5) returns the number of wanted converged Ritz values.', 2: 'No longer an informational error. Deprecated starting with release 2 of ARPACK.', 3: 'No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ', -1: 'N must be positive.', -2: 'NEV must be positive.', -3: 'NCV-NEV >= 2 and less than or equal to N.', -4: 'The maximum number of Arnoldi update iterations allowed must be greater than zero.', -5: \" WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\", -6: \"BMAT must be one of 'I' or 'G'.\", -7: 'Length of private work array WORKL is not sufficient.', -8: 'Error return from LAPACK eigenvalue calculation;', -9: 'Starting vector is zero.', -10: 'IPARAM(7) must be 1,2,3.', -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\", -12: 'IPARAM(1) must be equal to 0 or 1.', -13: \"NEV and WHICH = 'BE' are incompatible.\", -9999: 'Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.'}, 'c': {0: 'Normal exit.', 1: 'Maximum number of iterations taken. All possible eigenvalues of OP has been found. IPARAM(5) returns the number of wanted converged Ritz values.', 2: 'No longer an informational error. Deprecated starting with release 2 of ARPACK.', 3: 'No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ', -1: 'N must be positive.', -2: 'NEV must be positive.', -3: 'NCV-NEV >= 2 and less than or equal to N.', -4: 'The maximum number of Arnoldi update iterations allowed must be greater than zero.', -5: \" WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\", -6: \"BMAT must be one of 'I' or 'G'.\", -7: 'Length of private work array WORKL is not sufficient.', -8: 'Error return from LAPACK eigenvalue calculation;', -9: 'Starting vector is zero.', -10: 'IPARAM(7) must be 1,2,3.', -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\", -12: 'IPARAM(1) must be equal to 0 or 1.', -13: \"NEV and WHICH = 'BE' are incompatible.\", -9999: 'Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.'}})\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.RuntimeError:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class ArpackNoConvergence(ArpackError)\n",
      "     |  ARPACK iteration did not converge\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  eigenvalues : ndarray\n",
      "     |      Partial result. Converged eigenvalues.\n",
      "     |  eigenvectors : ndarray\n",
      "     |      Partial result. Converged eigenvectors.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ArpackNoConvergence\n",
      "     |      ArpackError\n",
      "     |      builtins.RuntimeError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, msg, eigenvalues, eigenvectors)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ArpackError:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.RuntimeError:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class LinearOperator(builtins.object)\n",
      "     |  Common interface for performing matrix vector products\n",
      "     |  \n",
      "     |  Many iterative methods (e.g. cg, gmres) do not need to know the\n",
      "     |  individual entries of a matrix to solve a linear system A*x=b.\n",
      "     |  Such solvers only require the computation of matrix vector\n",
      "     |  products, A*v where v is a dense vector.  This class serves as\n",
      "     |  an abstract interface between iterative solvers and matrix-like\n",
      "     |  objects.\n",
      "     |  \n",
      "     |  To construct a concrete LinearOperator, either pass appropriate\n",
      "     |  callables to the constructor of this class, or subclass it.\n",
      "     |  \n",
      "     |  A subclass must implement either one of the methods ``_matvec``\n",
      "     |  and ``_matmat``, and the attributes/properties ``shape`` (pair of\n",
      "     |  integers) and ``dtype`` (may be None). It may call the ``__init__``\n",
      "     |  on this class to have these attributes validated. Implementing\n",
      "     |  ``_matvec`` automatically implements ``_matmat`` (using a naive\n",
      "     |  algorithm) and vice-versa.\n",
      "     |  \n",
      "     |  Optionally, a subclass may implement ``_rmatvec`` or ``_adjoint``\n",
      "     |  to implement the Hermitian adjoint (conjugate transpose). As with\n",
      "     |  ``_matvec`` and ``_matmat``, implementing either ``_rmatvec`` or\n",
      "     |  ``_adjoint`` implements the other automatically. Implementing\n",
      "     |  ``_adjoint`` is preferable; ``_rmatvec`` is mostly there for\n",
      "     |  backwards compatibility.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  shape : tuple\n",
      "     |      Matrix dimensions (M,N).\n",
      "     |  matvec : callable f(v)\n",
      "     |      Returns returns A * v.\n",
      "     |  rmatvec : callable f(v)\n",
      "     |      Returns A^H * v, where A^H is the conjugate transpose of A.\n",
      "     |  matmat : callable f(V)\n",
      "     |      Returns A * V, where V is a dense matrix with dimensions (N,K).\n",
      "     |  dtype : dtype\n",
      "     |      Data type of the matrix.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  args : tuple\n",
      "     |      For linear operators describing products etc. of other linear\n",
      "     |      operators, the operands of the binary operation.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  aslinearoperator : Construct LinearOperators\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The user-defined matvec() function must properly handle the case\n",
      "     |  where v has shape (N,) as well as the (N,1) case.  The shape of\n",
      "     |  the return type is handled internally by LinearOperator.\n",
      "     |  \n",
      "     |  LinearOperator instances can also be multiplied, added with each\n",
      "     |  other and exponentiated, all lazily: the result of these operations\n",
      "     |  is always a new, composite LinearOperator, that defers linear\n",
      "     |  operations to the original operators and combines the results.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from scipy.sparse.linalg import LinearOperator\n",
      "     |  >>> def mv(v):\n",
      "     |  ...     return np.array([2*v[0], 3*v[1]])\n",
      "     |  ...\n",
      "     |  >>> A = LinearOperator((2,2), matvec=mv)\n",
      "     |  >>> A\n",
      "     |  <2x2 _CustomLinearOperator with dtype=float64>\n",
      "     |  >>> A.matvec(np.ones(2))\n",
      "     |  array([ 2.,  3.])\n",
      "     |  >>> A * np.ones(2)\n",
      "     |  array([ 2.,  3.])\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, x)\n",
      "     |  \n",
      "     |  __call__(self, x)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, dtype, shape)\n",
      "     |      Initialize this LinearOperator.\n",
      "     |      \n",
      "     |      To be called by subclasses. ``dtype`` may be None; ``shape`` should\n",
      "     |      be convertible to a length-2 tuple.\n",
      "     |  \n",
      "     |  __matmul__(self, other)\n",
      "     |  \n",
      "     |  __mul__(self, x)\n",
      "     |  \n",
      "     |  __neg__(self)\n",
      "     |  \n",
      "     |  __pow__(self, p)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmatmul__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(self, x)\n",
      "     |  \n",
      "     |  __sub__(self, x)\n",
      "     |  \n",
      "     |  adjoint(self)\n",
      "     |      Hermitian adjoint.\n",
      "     |      \n",
      "     |      Returns the Hermitian adjoint of self, aka the Hermitian\n",
      "     |      conjugate or Hermitian transpose. For a complex matrix, the\n",
      "     |      Hermitian adjoint is equal to the conjugate transpose.\n",
      "     |      \n",
      "     |      Can be abbreviated self.H instead of self.adjoint().\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A_H : LinearOperator\n",
      "     |          Hermitian adjoint of self.\n",
      "     |  \n",
      "     |  dot(self, x)\n",
      "     |      Matrix-matrix or matrix-vector multiplication.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          1-d or 2-d array, representing a vector or matrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Ax : array\n",
      "     |          1-d or 2-d array (depending on the shape of x) that represents\n",
      "     |          the result of applying this linear operator on x.\n",
      "     |  \n",
      "     |  matmat(self, X)\n",
      "     |      Matrix-matrix multiplication.\n",
      "     |      \n",
      "     |      Performs the operation y=A*X where A is an MxN linear\n",
      "     |      operator and X dense N*K matrix or ndarray.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {matrix, ndarray}\n",
      "     |          An array with shape (N,K).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Y : {matrix, ndarray}\n",
      "     |          A matrix or ndarray with shape (M,K) depending on\n",
      "     |          the type of the X argument.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This matmat wraps any user-specified matmat routine or overridden\n",
      "     |      _matmat method to ensure that y has the correct type.\n",
      "     |  \n",
      "     |  matvec(self, x)\n",
      "     |      Matrix-vector multiplication.\n",
      "     |      \n",
      "     |      Performs the operation y=A*x where A is an MxN linear\n",
      "     |      operator and x is a column vector or 1-d array.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : {matrix, ndarray}\n",
      "     |          An array with shape (N,) or (N,1).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : {matrix, ndarray}\n",
      "     |          A matrix or ndarray with shape (M,) or (M,1) depending\n",
      "     |          on the type and shape of the x argument.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This matvec wraps the user-specified matvec routine or overridden\n",
      "     |      _matvec method to ensure that y has the correct shape and type.\n",
      "     |  \n",
      "     |  rmatvec(self, x)\n",
      "     |      Adjoint matrix-vector multiplication.\n",
      "     |      \n",
      "     |      Performs the operation y = A^H * x where A is an MxN linear\n",
      "     |      operator and x is a column vector or 1-d array.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : {matrix, ndarray}\n",
      "     |          An array with shape (M,) or (M,1).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : {matrix, ndarray}\n",
      "     |          A matrix or ndarray with shape (N,) or (N,1) depending\n",
      "     |          on the type and shape of the x argument.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This rmatvec wraps the user-specified rmatvec routine or overridden\n",
      "     |      _rmatvec method to ensure that y has the correct shape and type.\n",
      "     |  \n",
      "     |  transpose(self)\n",
      "     |      Transpose this linear operator.\n",
      "     |      \n",
      "     |      Returns a LinearOperator that represents the transpose of this one.\n",
      "     |      Can be abbreviated self.T instead of self.transpose().\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwargs)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  H\n",
      "     |      Hermitian adjoint.\n",
      "     |      \n",
      "     |      Returns the Hermitian adjoint of self, aka the Hermitian\n",
      "     |      conjugate or Hermitian transpose. For a complex matrix, the\n",
      "     |      Hermitian adjoint is equal to the conjugate transpose.\n",
      "     |      \n",
      "     |      Can be abbreviated self.H instead of self.adjoint().\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A_H : LinearOperator\n",
      "     |          Hermitian adjoint of self.\n",
      "     |  \n",
      "     |  T\n",
      "     |      Transpose this linear operator.\n",
      "     |      \n",
      "     |      Returns a LinearOperator that represents the transpose of this one.\n",
      "     |      Can be abbreviated self.T instead of self.transpose().\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MatrixRankWarning(builtins.UserWarning)\n",
      "     |  Base class for warnings generated by user code.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MatrixRankWarning\n",
      "     |      builtins.UserWarning\n",
      "     |      builtins.Warning\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.UserWarning:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class SuperLU(object)\n",
      "     |  LU factorization of a sparse matrix.\n",
      "     |  \n",
      "     |  Factorization is represented as::\n",
      "     |  \n",
      "     |      Pr * A * Pc = L * U\n",
      "     |  \n",
      "     |  To construct these `SuperLU` objects, call the `splu` and `spilu`\n",
      "     |  functions.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  shape\n",
      "     |  nnz\n",
      "     |  perm_c\n",
      "     |  perm_r\n",
      "     |  L\n",
      "     |  U\n",
      "     |  \n",
      "     |  Methods\n",
      "     |  -------\n",
      "     |  solve\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  \n",
      "     |  .. versionadded:: 0.14.0\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  The LU decomposition can be used to solve matrix equations. Consider:\n",
      "     |  \n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from scipy.sparse import csc_matrix, linalg as sla\n",
      "     |  >>> A = csc_matrix([[1,2,0,4],[1,0,0,1],[1,0,2,1],[2,2,1,0.]])\n",
      "     |  \n",
      "     |  This can be solved for a given right-hand side:\n",
      "     |  \n",
      "     |  >>> lu = sla.splu(A)\n",
      "     |  >>> b = np.array([1, 2, 3, 4])\n",
      "     |  >>> x = lu.solve(b)\n",
      "     |  >>> A.dot(x)\n",
      "     |  array([ 1.,  2.,  3.,  4.])\n",
      "     |  \n",
      "     |  The ``lu`` object also contains an explicit representation of the\n",
      "     |  decomposition. The permutations are represented as mappings of\n",
      "     |  indices:\n",
      "     |  \n",
      "     |  >>> lu.perm_r\n",
      "     |  array([0, 2, 1, 3], dtype=int32)\n",
      "     |  >>> lu.perm_c\n",
      "     |  array([2, 0, 1, 3], dtype=int32)\n",
      "     |  \n",
      "     |  The L and U factors are sparse matrices in CSC format:\n",
      "     |  \n",
      "     |  >>> lu.L.A\n",
      "     |  array([[ 1. ,  0. ,  0. ,  0. ],\n",
      "     |         [ 0. ,  1. ,  0. ,  0. ],\n",
      "     |         [ 0. ,  0. ,  1. ,  0. ],\n",
      "     |         [ 1. ,  0.5,  0.5,  1. ]])\n",
      "     |  >>> lu.U.A\n",
      "     |  array([[ 2.,  0.,  1.,  4.],\n",
      "     |         [ 0.,  2.,  1.,  1.],\n",
      "     |         [ 0.,  0.,  1.,  1.],\n",
      "     |         [ 0.,  0.,  0., -5.]])\n",
      "     |  \n",
      "     |  The permutation matrices can be constructed:\n",
      "     |  \n",
      "     |  >>> Pr = csc_matrix((4, 4))\n",
      "     |  >>> Pr[lu.perm_r, np.arange(4)] = 1\n",
      "     |  >>> Pc = csc_matrix((4, 4))\n",
      "     |  >>> Pc[np.arange(4), lu.perm_c] = 1\n",
      "     |  \n",
      "     |  We can reassemble the original matrix:\n",
      "     |  \n",
      "     |  >>> (Pr.T * (lu.L * lu.U) * Pc.T).A\n",
      "     |  array([[ 1.,  2.,  0.,  4.],\n",
      "     |         [ 1.,  0.,  0.,  1.],\n",
      "     |         [ 1.,  0.,  2.,  1.],\n",
      "     |         [ 2.,  2.,  1.,  0.]])\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(rhs[, trans])\n",
      "     |      \n",
      "     |      Solves linear system of equations with one or several right-hand sides.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rhs : ndarray, shape (n,) or (n, k)\n",
      "     |          Right hand side(s) of equation\n",
      "     |      trans : {'N', 'T', 'H'}, optional\n",
      "     |          Type of system to solve::\n",
      "     |      \n",
      "     |              'N':   A   * x == rhs  (default)\n",
      "     |              'T':   A^T * x == rhs\n",
      "     |              'H':   A^H * x == rhs\n",
      "     |      \n",
      "     |          i.e., normal, transposed, and hermitian conjugate.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      x : ndarray, shape ``rhs.shape``\n",
      "     |          Solution vector(s)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  L\n",
      "     |      Lower triangular factor with unit diagonal as a\n",
      "     |      `scipy.sparse.csc_matrix`.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.14.0\n",
      "     |  \n",
      "     |  U\n",
      "     |      Upper triangular factor as a `scipy.sparse.csc_matrix`.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.14.0\n",
      "     |  \n",
      "     |  nnz\n",
      "     |      Number of nonzero elements in the matrix.\n",
      "     |  \n",
      "     |  perm_c\n",
      "     |      Permutation Pc represented as an array of indices.\n",
      "     |      \n",
      "     |      The column permutation matrix can be reconstructed via:\n",
      "     |      \n",
      "     |      >>> Pc = np.zeros((n, n))\n",
      "     |      >>> Pc[np.arange(n), perm_c] = 1\n",
      "     |  \n",
      "     |  perm_r\n",
      "     |      Permutation Pr represented as an array of indices.\n",
      "     |      \n",
      "     |      The row permutation matrix can be reconstructed via:\n",
      "     |      \n",
      "     |      >>> Pr = np.zeros((n, n))\n",
      "     |      >>> Pr[perm_r, np.arange(n)] = 1\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Shape of the original matrix as a tuple of ints.\n",
      "\n",
      "FUNCTIONS\n",
      "    aslinearoperator(A)\n",
      "        Return A as a LinearOperator.\n",
      "        \n",
      "        'A' may be any of the following types:\n",
      "         - ndarray\n",
      "         - matrix\n",
      "         - sparse matrix (e.g. csr_matrix, lil_matrix, etc.)\n",
      "         - LinearOperator\n",
      "         - An object with .shape and .matvec attributes\n",
      "        \n",
      "        See the LinearOperator documentation for additional information.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse.linalg import aslinearoperator\n",
      "        >>> M = np.array([[1,2,3],[4,5,6]], dtype=np.int32)\n",
      "        >>> aslinearoperator(M)\n",
      "        <2x3 MatrixLinearOperator with dtype=int32>\n",
      "    \n",
      "    bicg(A, b, x0=None, tol=1e-05, maxiter=None, M=None, callback=None)\n",
      "        Use BIConjugate Gradient iteration to solve ``Ax = b``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, dense matrix, LinearOperator}\n",
      "            The real or complex N-by-N matrix of the linear system.\n",
      "            It is required that the linear operator can produce\n",
      "            ``Ax`` and ``A^T x``.\n",
      "        b : {array, matrix}\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : {array, matrix}\n",
      "            The converged solution.\n",
      "        info : integer\n",
      "            Provides convergence information:\n",
      "                0  : successful exit\n",
      "                >0 : convergence to tolerance not achieved, number of iterations\n",
      "                <0 : illegal input or breakdown\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        x0  : {array, matrix}\n",
      "            Starting guess for the solution.\n",
      "        tol : float\n",
      "            Tolerance to achieve. The algorithm terminates when either the relative\n",
      "            or the absolute residual is below `tol`.\n",
      "        maxiter : integer\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, dense matrix, LinearOperator}\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A.  Effective preconditioning dramatically improves the\n",
      "            rate of convergence, which implies that fewer iterations are needed\n",
      "            to reach a given error tolerance.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "    \n",
      "    bicgstab(A, b, x0=None, tol=1e-05, maxiter=None, M=None, callback=None)\n",
      "        Use BIConjugate Gradient STABilized iteration to solve ``Ax = b``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, dense matrix, LinearOperator}\n",
      "            The real or complex N-by-N matrix of the linear system.\n",
      "        b : {array, matrix}\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : {array, matrix}\n",
      "            The converged solution.\n",
      "        info : integer\n",
      "            Provides convergence information:\n",
      "                0  : successful exit\n",
      "                >0 : convergence to tolerance not achieved, number of iterations\n",
      "                <0 : illegal input or breakdown\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        x0  : {array, matrix}\n",
      "            Starting guess for the solution.\n",
      "        tol : float\n",
      "            Tolerance to achieve. The algorithm terminates when either the relative\n",
      "            or the absolute residual is below `tol`.\n",
      "        maxiter : integer\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, dense matrix, LinearOperator}\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A.  Effective preconditioning dramatically improves the\n",
      "            rate of convergence, which implies that fewer iterations are needed\n",
      "            to reach a given error tolerance.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "    \n",
      "    cg(A, b, x0=None, tol=1e-05, maxiter=None, M=None, callback=None)\n",
      "        Use Conjugate Gradient iteration to solve ``Ax = b``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, dense matrix, LinearOperator}\n",
      "            The real or complex N-by-N matrix of the linear system.\n",
      "            ``A`` must represent a hermitian, positive definite matrix.\n",
      "        b : {array, matrix}\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : {array, matrix}\n",
      "            The converged solution.\n",
      "        info : integer\n",
      "            Provides convergence information:\n",
      "                0  : successful exit\n",
      "                >0 : convergence to tolerance not achieved, number of iterations\n",
      "                <0 : illegal input or breakdown\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        x0  : {array, matrix}\n",
      "            Starting guess for the solution.\n",
      "        tol : float\n",
      "            Tolerance to achieve. The algorithm terminates when either the relative\n",
      "            or the absolute residual is below `tol`.\n",
      "        maxiter : integer\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, dense matrix, LinearOperator}\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A.  Effective preconditioning dramatically improves the\n",
      "            rate of convergence, which implies that fewer iterations are needed\n",
      "            to reach a given error tolerance.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "    \n",
      "    cgs(A, b, x0=None, tol=1e-05, maxiter=None, M=None, callback=None)\n",
      "        Use Conjugate Gradient Squared iteration to solve ``Ax = b``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, dense matrix, LinearOperator}\n",
      "            The real-valued N-by-N matrix of the linear system.\n",
      "        b : {array, matrix}\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : {array, matrix}\n",
      "            The converged solution.\n",
      "        info : integer\n",
      "            Provides convergence information:\n",
      "                0  : successful exit\n",
      "                >0 : convergence to tolerance not achieved, number of iterations\n",
      "                <0 : illegal input or breakdown\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        x0  : {array, matrix}\n",
      "            Starting guess for the solution.\n",
      "        tol : float\n",
      "            Tolerance to achieve. The algorithm terminates when either the relative\n",
      "            or the absolute residual is below `tol`.\n",
      "        maxiter : integer\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, dense matrix, LinearOperator}\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A.  Effective preconditioning dramatically improves the\n",
      "            rate of convergence, which implies that fewer iterations are needed\n",
      "            to reach a given error tolerance.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "    \n",
      "    eigs(A, k=6, M=None, sigma=None, which='LM', v0=None, ncv=None, maxiter=None, tol=0, return_eigenvectors=True, Minv=None, OPinv=None, OPpart=None)\n",
      "        Find k eigenvalues and eigenvectors of the square matrix A.\n",
      "        \n",
      "        Solves ``A * x[i] = w[i] * x[i]``, the standard eigenvalue problem\n",
      "        for w[i] eigenvalues with corresponding eigenvectors x[i].\n",
      "        \n",
      "        If M is specified, solves ``A * x[i] = w[i] * M * x[i]``, the\n",
      "        generalized eigenvalue problem for w[i] eigenvalues\n",
      "        with corresponding eigenvectors x[i]\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : ndarray, sparse matrix or LinearOperator\n",
      "            An array, sparse matrix, or LinearOperator representing\n",
      "            the operation ``A * x``, where A is a real or complex square matrix.\n",
      "        k : int, optional\n",
      "            The number of eigenvalues and eigenvectors desired.\n",
      "            `k` must be smaller than N-1. It is not possible to compute all\n",
      "            eigenvectors of a matrix.\n",
      "        M : ndarray, sparse matrix or LinearOperator, optional\n",
      "            An array, sparse matrix, or LinearOperator representing\n",
      "            the operation M*x for the generalized eigenvalue problem\n",
      "        \n",
      "                A * x = w * M * x.\n",
      "        \n",
      "            M must represent a real, symmetric matrix if A is real, and must\n",
      "            represent a complex, hermitian matrix if A is complex. For best\n",
      "            results, the data type of M should be the same as that of A.\n",
      "            Additionally:\n",
      "        \n",
      "                If `sigma` is None, M is positive definite\n",
      "        \n",
      "                If sigma is specified, M is positive semi-definite\n",
      "        \n",
      "            If sigma is None, eigs requires an operator to compute the solution\n",
      "            of the linear equation ``M * x = b``.  This is done internally via a\n",
      "            (sparse) LU decomposition for an explicit matrix M, or via an\n",
      "            iterative solver for a general linear operator.  Alternatively,\n",
      "            the user can supply the matrix or operator Minv, which gives\n",
      "            ``x = Minv * b = M^-1 * b``.\n",
      "        sigma : real or complex, optional\n",
      "            Find eigenvalues near sigma using shift-invert mode.  This requires\n",
      "            an operator to compute the solution of the linear system\n",
      "            ``[A - sigma * M] * x = b``, where M is the identity matrix if\n",
      "            unspecified. This is computed internally via a (sparse) LU\n",
      "            decomposition for explicit matrices A & M, or via an iterative\n",
      "            solver if either A or M is a general linear operator.\n",
      "            Alternatively, the user can supply the matrix or operator OPinv,\n",
      "            which gives ``x = OPinv * b = [A - sigma * M]^-1 * b``.\n",
      "            For a real matrix A, shift-invert can either be done in imaginary\n",
      "            mode or real mode, specified by the parameter OPpart ('r' or 'i').\n",
      "            Note that when sigma is specified, the keyword 'which' (below)\n",
      "            refers to the shifted eigenvalues ``w'[i]`` where:\n",
      "        \n",
      "                If A is real and OPpart == 'r' (default),\n",
      "                  ``w'[i] = 1/2 * [1/(w[i]-sigma) + 1/(w[i]-conj(sigma))]``.\n",
      "        \n",
      "                If A is real and OPpart == 'i',\n",
      "                  ``w'[i] = 1/2i * [1/(w[i]-sigma) - 1/(w[i]-conj(sigma))]``.\n",
      "        \n",
      "                If A is complex, ``w'[i] = 1/(w[i]-sigma)``.\n",
      "        \n",
      "        v0 : ndarray, optional\n",
      "            Starting vector for iteration.\n",
      "            Default: random\n",
      "        ncv : int, optional\n",
      "            The number of Lanczos vectors generated\n",
      "            `ncv` must be greater than `k`; it is recommended that ``ncv > 2*k``.\n",
      "            Default: ``min(n, max(2*k + 1, 20))``\n",
      "        which : str, ['LM' | 'SM' | 'LR' | 'SR' | 'LI' | 'SI'], optional\n",
      "            Which `k` eigenvectors and eigenvalues to find:\n",
      "        \n",
      "                'LM' : largest magnitude\n",
      "        \n",
      "                'SM' : smallest magnitude\n",
      "        \n",
      "                'LR' : largest real part\n",
      "        \n",
      "                'SR' : smallest real part\n",
      "        \n",
      "                'LI' : largest imaginary part\n",
      "        \n",
      "                'SI' : smallest imaginary part\n",
      "        \n",
      "            When sigma != None, 'which' refers to the shifted eigenvalues w'[i]\n",
      "            (see discussion in 'sigma', above).  ARPACK is generally better\n",
      "            at finding large values than small values.  If small eigenvalues are\n",
      "            desired, consider using shift-invert mode for better performance.\n",
      "        maxiter : int, optional\n",
      "            Maximum number of Arnoldi update iterations allowed\n",
      "            Default: ``n*10``\n",
      "        tol : float, optional\n",
      "            Relative accuracy for eigenvalues (stopping criterion)\n",
      "            The default value of 0 implies machine precision.\n",
      "        return_eigenvectors : bool, optional\n",
      "            Return eigenvectors (True) in addition to eigenvalues\n",
      "        Minv : ndarray, sparse matrix or LinearOperator, optional\n",
      "            See notes in M, above.\n",
      "        OPinv : ndarray, sparse matrix or LinearOperator, optional\n",
      "            See notes in sigma, above.\n",
      "        OPpart : {'r' or 'i'}, optional\n",
      "            See notes in sigma, above\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : ndarray\n",
      "            Array of k eigenvalues.\n",
      "        v : ndarray\n",
      "            An array of `k` eigenvectors.\n",
      "            ``v[:, i]`` is the eigenvector corresponding to the eigenvalue w[i].\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        ArpackNoConvergence\n",
      "            When the requested convergence is not obtained.\n",
      "            The currently converged eigenvalues and eigenvectors can be found\n",
      "            as ``eigenvalues`` and ``eigenvectors`` attributes of the exception\n",
      "            object.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        eigsh : eigenvalues and eigenvectors for symmetric matrix A\n",
      "        svds : singular value decomposition for a matrix A\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function is a wrapper to the ARPACK [1]_ SNEUPD, DNEUPD, CNEUPD,\n",
      "        ZNEUPD, functions which use the Implicitly Restarted Arnoldi Method to\n",
      "        find the eigenvalues and eigenvectors [2]_.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] ARPACK Software, http://www.caam.rice.edu/software/ARPACK/\n",
      "        .. [2] R. B. Lehoucq, D. C. Sorensen, and C. Yang,  ARPACK USERS GUIDE:\n",
      "           Solution of Large Scale Eigenvalue Problems by Implicitly Restarted\n",
      "           Arnoldi Methods. SIAM, Philadelphia, PA, 1998.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Find 6 eigenvectors of the identity matrix:\n",
      "        \n",
      "        >>> import scipy.sparse as sparse\n",
      "        >>> id = np.eye(13)\n",
      "        >>> vals, vecs = sparse.linalg.eigs(id, k=6)\n",
      "        >>> vals\n",
      "        array([ 1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j])\n",
      "        >>> vecs.shape\n",
      "        (13, 6)\n",
      "    \n",
      "    eigsh(A, k=6, M=None, sigma=None, which='LM', v0=None, ncv=None, maxiter=None, tol=0, return_eigenvectors=True, Minv=None, OPinv=None, mode='normal')\n",
      "        Find k eigenvalues and eigenvectors of the real symmetric square matrix\n",
      "        or complex hermitian matrix A.\n",
      "        \n",
      "        Solves ``A * x[i] = w[i] * x[i]``, the standard eigenvalue problem for\n",
      "        w[i] eigenvalues with corresponding eigenvectors x[i].\n",
      "        \n",
      "        If M is specified, solves ``A * x[i] = w[i] * M * x[i]``, the\n",
      "        generalized eigenvalue problem for w[i] eigenvalues\n",
      "        with corresponding eigenvectors x[i]\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : An N x N matrix, array, sparse matrix, or LinearOperator representing\n",
      "            the operation A * x, where A is a real symmetric matrix\n",
      "            For buckling mode (see below) A must additionally be positive-definite\n",
      "        k : int, optional\n",
      "            The number of eigenvalues and eigenvectors desired.\n",
      "            `k` must be smaller than N. It is not possible to compute all\n",
      "            eigenvectors of a matrix.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : array\n",
      "            Array of k eigenvalues\n",
      "        v : array\n",
      "            An array representing the `k` eigenvectors.  The column ``v[:, i]`` is\n",
      "            the eigenvector corresponding to the eigenvalue ``w[i]``.\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        M : An N x N matrix, array, sparse matrix, or linear operator representing\n",
      "            the operation M * x for the generalized eigenvalue problem\n",
      "        \n",
      "                A * x = w * M * x.\n",
      "        \n",
      "            M must represent a real, symmetric matrix if A is real, and must\n",
      "            represent a complex, hermitian matrix if A is complex. For best\n",
      "            results, the data type of M should be the same as that of A.\n",
      "            Additionally:\n",
      "        \n",
      "                If sigma is None, M is symmetric positive definite\n",
      "        \n",
      "                If sigma is specified, M is symmetric positive semi-definite\n",
      "        \n",
      "                In buckling mode, M is symmetric indefinite.\n",
      "        \n",
      "            If sigma is None, eigsh requires an operator to compute the solution\n",
      "            of the linear equation ``M * x = b``. This is done internally via a\n",
      "            (sparse) LU decomposition for an explicit matrix M, or via an\n",
      "            iterative solver for a general linear operator.  Alternatively,\n",
      "            the user can supply the matrix or operator Minv, which gives\n",
      "            ``x = Minv * b = M^-1 * b``.\n",
      "        sigma : real\n",
      "            Find eigenvalues near sigma using shift-invert mode.  This requires\n",
      "            an operator to compute the solution of the linear system\n",
      "            `[A - sigma * M] x = b`, where M is the identity matrix if\n",
      "            unspecified.  This is computed internally via a (sparse) LU\n",
      "            decomposition for explicit matrices A & M, or via an iterative\n",
      "            solver if either A or M is a general linear operator.\n",
      "            Alternatively, the user can supply the matrix or operator OPinv,\n",
      "            which gives ``x = OPinv * b = [A - sigma * M]^-1 * b``.\n",
      "            Note that when sigma is specified, the keyword 'which' refers to\n",
      "            the shifted eigenvalues ``w'[i]`` where:\n",
      "        \n",
      "                if mode == 'normal', ``w'[i] = 1 / (w[i] - sigma)``.\n",
      "        \n",
      "                if mode == 'cayley', ``w'[i] = (w[i] + sigma) / (w[i] - sigma)``.\n",
      "        \n",
      "                if mode == 'buckling', ``w'[i] = w[i] / (w[i] - sigma)``.\n",
      "        \n",
      "            (see further discussion in 'mode' below)\n",
      "        v0 : ndarray, optional\n",
      "            Starting vector for iteration.\n",
      "            Default: random\n",
      "        ncv : int, optional\n",
      "            The number of Lanczos vectors generated ncv must be greater than k and\n",
      "            smaller than n; it is recommended that ``ncv > 2*k``.\n",
      "            Default: ``min(n, max(2*k + 1, 20))``\n",
      "        which : str ['LM' | 'SM' | 'LA' | 'SA' | 'BE']\n",
      "            If A is a complex hermitian matrix, 'BE' is invalid.\n",
      "            Which `k` eigenvectors and eigenvalues to find:\n",
      "        \n",
      "                'LM' : Largest (in magnitude) eigenvalues\n",
      "        \n",
      "                'SM' : Smallest (in magnitude) eigenvalues\n",
      "        \n",
      "                'LA' : Largest (algebraic) eigenvalues\n",
      "        \n",
      "                'SA' : Smallest (algebraic) eigenvalues\n",
      "        \n",
      "                'BE' : Half (k/2) from each end of the spectrum\n",
      "        \n",
      "            When k is odd, return one more (k/2+1) from the high end.\n",
      "            When sigma != None, 'which' refers to the shifted eigenvalues ``w'[i]``\n",
      "            (see discussion in 'sigma', above).  ARPACK is generally better\n",
      "            at finding large values than small values.  If small eigenvalues are\n",
      "            desired, consider using shift-invert mode for better performance.\n",
      "        maxiter : int, optional\n",
      "            Maximum number of Arnoldi update iterations allowed\n",
      "            Default: ``n*10``\n",
      "        tol : float\n",
      "            Relative accuracy for eigenvalues (stopping criterion).\n",
      "            The default value of 0 implies machine precision.\n",
      "        Minv : N x N matrix, array, sparse matrix, or LinearOperator\n",
      "            See notes in M, above\n",
      "        OPinv : N x N matrix, array, sparse matrix, or LinearOperator\n",
      "            See notes in sigma, above.\n",
      "        return_eigenvectors : bool\n",
      "            Return eigenvectors (True) in addition to eigenvalues\n",
      "        mode : string ['normal' | 'buckling' | 'cayley']\n",
      "            Specify strategy to use for shift-invert mode.  This argument applies\n",
      "            only for real-valued A and sigma != None.  For shift-invert mode,\n",
      "            ARPACK internally solves the eigenvalue problem\n",
      "            ``OP * x'[i] = w'[i] * B * x'[i]``\n",
      "            and transforms the resulting Ritz vectors x'[i] and Ritz values w'[i]\n",
      "            into the desired eigenvectors and eigenvalues of the problem\n",
      "            ``A * x[i] = w[i] * M * x[i]``.\n",
      "            The modes are as follows:\n",
      "        \n",
      "                'normal' :\n",
      "                    OP = [A - sigma * M]^-1 * M,\n",
      "                    B = M,\n",
      "                    w'[i] = 1 / (w[i] - sigma)\n",
      "        \n",
      "                'buckling' :\n",
      "                    OP = [A - sigma * M]^-1 * A,\n",
      "                    B = A,\n",
      "                    w'[i] = w[i] / (w[i] - sigma)\n",
      "        \n",
      "                'cayley' :\n",
      "                    OP = [A - sigma * M]^-1 * [A + sigma * M],\n",
      "                    B = M,\n",
      "                    w'[i] = (w[i] + sigma) / (w[i] - sigma)\n",
      "        \n",
      "            The choice of mode will affect which eigenvalues are selected by\n",
      "            the keyword 'which', and can also impact the stability of\n",
      "            convergence (see [2] for a discussion)\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        ArpackNoConvergence\n",
      "            When the requested convergence is not obtained.\n",
      "        \n",
      "            The currently converged eigenvalues and eigenvectors can be found\n",
      "            as ``eigenvalues`` and ``eigenvectors`` attributes of the exception\n",
      "            object.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        eigs : eigenvalues and eigenvectors for a general (nonsymmetric) matrix A\n",
      "        svds : singular value decomposition for a matrix A\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function is a wrapper to the ARPACK [1]_ SSEUPD and DSEUPD\n",
      "        functions which use the Implicitly Restarted Lanczos Method to\n",
      "        find the eigenvalues and eigenvectors [2]_.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] ARPACK Software, http://www.caam.rice.edu/software/ARPACK/\n",
      "        .. [2] R. B. Lehoucq, D. C. Sorensen, and C. Yang,  ARPACK USERS GUIDE:\n",
      "           Solution of Large Scale Eigenvalue Problems by Implicitly Restarted\n",
      "           Arnoldi Methods. SIAM, Philadelphia, PA, 1998.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import scipy.sparse as sparse\n",
      "        >>> id = np.eye(13)\n",
      "        >>> vals, vecs = sparse.linalg.eigsh(id, k=6)\n",
      "        >>> vals\n",
      "        array([ 1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j])\n",
      "        >>> vecs.shape\n",
      "        (13, 6)\n",
      "    \n",
      "    expm(A)\n",
      "        Compute the matrix exponential using Pade approximation.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : (M,M) array_like or sparse matrix\n",
      "            2D Array or Matrix (sparse or dense) to be exponentiated\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        expA : (M,M) ndarray\n",
      "            Matrix exponential of `A`\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is algorithm (6.1) which is a simplification of algorithm (5.1).\n",
      "        \n",
      "        .. versionadded:: 0.12.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Awad H. Al-Mohy and Nicholas J. Higham (2009)\n",
      "               \"A New Scaling and Squaring Algorithm for the Matrix Exponential.\"\n",
      "               SIAM Journal on Matrix Analysis and Applications.\n",
      "               31 (3). pp. 970-989. ISSN 1095-7162\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import expm\n",
      "        >>> A = csc_matrix([[1, 0, 0], [0, 2, 0], [0, 0, 3]])\n",
      "        >>> A.todense()\n",
      "        matrix([[1, 0, 0],\n",
      "                [0, 2, 0],\n",
      "                [0, 0, 3]], dtype=int64)\n",
      "        >>> Aexp = expm(A)\n",
      "        >>> Aexp\n",
      "        <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "            with 3 stored elements in Compressed Sparse Column format>\n",
      "        >>> Aexp.todense()\n",
      "        matrix([[  2.71828183,   0.        ,   0.        ],\n",
      "                [  0.        ,   7.3890561 ,   0.        ],\n",
      "                [  0.        ,   0.        ,  20.08553692]])\n",
      "    \n",
      "    expm_multiply(A, B, start=None, stop=None, num=None, endpoint=None)\n",
      "        Compute the action of the matrix exponential of A on B.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : transposable linear operator\n",
      "            The operator whose exponential is of interest.\n",
      "        B : ndarray\n",
      "            The matrix or vector to be multiplied by the matrix exponential of A.\n",
      "        start : scalar, optional\n",
      "            The starting time point of the sequence.\n",
      "        stop : scalar, optional\n",
      "            The end time point of the sequence, unless `endpoint` is set to False.\n",
      "            In that case, the sequence consists of all but the last of ``num + 1``\n",
      "            evenly spaced time points, so that `stop` is excluded.\n",
      "            Note that the step size changes when `endpoint` is False.\n",
      "        num : int, optional\n",
      "            Number of time points to use.\n",
      "        endpoint : bool, optional\n",
      "            If True, `stop` is the last time point.  Otherwise, it is not included.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        expm_A_B : ndarray\n",
      "             The result of the action :math:`e^{t_k A} B`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The optional arguments defining the sequence of evenly spaced time points\n",
      "        are compatible with the arguments of `numpy.linspace`.\n",
      "        \n",
      "        The output ndarray shape is somewhat complicated so I explain it here.\n",
      "        The ndim of the output could be either 1, 2, or 3.\n",
      "        It would be 1 if you are computing the expm action on a single vector\n",
      "        at a single time point.\n",
      "        It would be 2 if you are computing the expm action on a vector\n",
      "        at multiple time points, or if you are computing the expm action\n",
      "        on a matrix at a single time point.\n",
      "        It would be 3 if you want the action on a matrix with multiple\n",
      "        columns at multiple time points.\n",
      "        If multiple time points are requested, expm_A_B[0] will always\n",
      "        be the action of the expm at the first time point,\n",
      "        regardless of whether the action is on a vector or a matrix.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Awad H. Al-Mohy and Nicholas J. Higham (2011)\n",
      "               \"Computing the Action of the Matrix Exponential,\n",
      "               with an Application to Exponential Integrators.\"\n",
      "               SIAM Journal on Scientific Computing,\n",
      "               33 (2). pp. 488-511. ISSN 1064-8275\n",
      "               http://eprints.ma.man.ac.uk/1591/\n",
      "        \n",
      "        .. [2] Nicholas J. Higham and Awad H. Al-Mohy (2010)\n",
      "               \"Computing Matrix Functions.\"\n",
      "               Acta Numerica,\n",
      "               19. 159-208. ISSN 0962-4929\n",
      "               http://eprints.ma.man.ac.uk/1451/\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import expm, expm_multiply\n",
      "        >>> A = csc_matrix([[1, 0], [0, 1]])\n",
      "        >>> A.todense()\n",
      "        matrix([[1, 0],\n",
      "                [0, 1]], dtype=int64)\n",
      "        >>> B = np.array([np.exp(-1.), np.exp(-2.)])\n",
      "        >>> B\n",
      "        array([ 0.36787944,  0.13533528])\n",
      "        >>> expm_multiply(A, B, start=1, stop=2, num=3, endpoint=True)\n",
      "        array([[ 1.        ,  0.36787944],\n",
      "               [ 1.64872127,  0.60653066],\n",
      "               [ 2.71828183,  1.        ]])\n",
      "        >>> expm(A).dot(B)                  # Verify 1st timestep\n",
      "        array([ 1.        ,  0.36787944])\n",
      "        >>> expm(1.5*A).dot(B)              # Verify 2nd timestep\n",
      "        array([ 1.64872127,  0.60653066])\n",
      "        >>> expm(2*A).dot(B)                # Verify 3rd timestep\n",
      "        array([ 2.71828183,  1.        ])\n",
      "    \n",
      "    factorized(A)\n",
      "        Return a function for solving a sparse linear system, with A pre-factorized.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : (N, N) array_like\n",
      "            Input.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        solve : callable\n",
      "            To solve the linear system of equations given in `A`, the `solve`\n",
      "            callable should be passed an ndarray of shape (N,).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse.linalg import factorized\n",
      "        >>> A = np.array([[ 3. ,  2. , -1. ],\n",
      "        ...               [ 2. , -2. ,  4. ],\n",
      "        ...               [-1. ,  0.5, -1. ]])\n",
      "        >>> solve = factorized(A) # Makes LU decomposition.\n",
      "        >>> rhs1 = np.array([1, -2, 0])\n",
      "        >>> solve(rhs1) # Uses the LU factors.\n",
      "        array([ 1., -2., -2.])\n",
      "    \n",
      "    gcrotmk(A, b, x0=None, tol=1e-05, maxiter=1000, M=None, callback=None, m=20, k=None, CU=None, discard_C=False, truncate='oldest')\n",
      "        Solve a matrix equation using flexible GCROT(m,k) algorithm.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, dense matrix, LinearOperator}\n",
      "            The real or complex N-by-N matrix of the linear system.\n",
      "        b : {array, matrix}\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        x0  : {array, matrix}\n",
      "            Starting guess for the solution.\n",
      "        tol : float, optional\n",
      "            Tolerance to achieve. The algorithm terminates when either the relative\n",
      "            or the absolute residual is below `tol`.\n",
      "        maxiter : int, optional\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, dense matrix, LinearOperator}, optional\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A. gcrotmk is a 'flexible' algorithm and the preconditioner\n",
      "            can vary from iteration to iteration. Effective preconditioning\n",
      "            dramatically improves the rate of convergence, which implies that\n",
      "            fewer iterations are needed to reach a given error tolerance.\n",
      "        callback : function, optional\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "        m : int, optional\n",
      "            Number of inner FGMRES iterations per each outer iteration.\n",
      "            Default: 20\n",
      "        k : int, optional\n",
      "            Number of vectors to carry between inner FGMRES iterations.\n",
      "            According to [2]_, good values are around m.\n",
      "            Default: m\n",
      "        CU : list of tuples, optional\n",
      "            List of tuples ``(c, u)`` which contain the columns of the matrices\n",
      "            C and U in the GCROT(m,k) algorithm. For details, see [2]_.\n",
      "            The list given and vectors contained in it are modified in-place.\n",
      "            If not given, start from empty matrices. The ``c`` elements in the\n",
      "            tuples can be ``None``, in which case the vectors are recomputed\n",
      "            via ``c = A u`` on start and orthogonalized as described in [3]_.\n",
      "        discard_C : bool, optional\n",
      "            Discard the C-vectors at the end. Useful if recycling Krylov subspaces\n",
      "            for different linear systems.\n",
      "        truncate : {'oldest', 'smallest'}, optional\n",
      "            Truncation scheme to use. Drop: oldest vectors, or vectors with\n",
      "            smallest singular values using the scheme discussed in [1,2].\n",
      "            See [2]_ for detailed comparison.\n",
      "            Default: 'oldest'\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : array or matrix\n",
      "            The solution found.\n",
      "        info : int\n",
      "            Provides convergence information:\n",
      "        \n",
      "            * 0  : successful exit\n",
      "            * >0 : convergence to tolerance not achieved, number of iterations\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] E. de Sturler, ''Truncation strategies for optimal Krylov subspace\n",
      "               methods'', SIAM J. Numer. Anal. 36, 864 (1999).\n",
      "        .. [2] J.E. Hicken and D.W. Zingg, ''A simplified and flexible variant\n",
      "               of GCROT for solving nonsymmetric linear systems'',\n",
      "               SIAM J. Sci. Comput. 32, 172 (2010).\n",
      "        .. [3] M.L. Parks, E. de Sturler, G. Mackey, D.D. Johnson, S. Maiti,\n",
      "               ''Recycling Krylov subspaces for sequences of linear systems'',\n",
      "               SIAM J. Sci. Comput. 28, 1651 (2006).\n",
      "    \n",
      "    gmres(A, b, x0=None, tol=1e-05, restart=None, maxiter=None, M=None, callback=None, restrt=None)\n",
      "        Use Generalized Minimal RESidual iteration to solve ``Ax = b``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, dense matrix, LinearOperator}\n",
      "            The real or complex N-by-N matrix of the linear system.\n",
      "        b : {array, matrix}\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : {array, matrix}\n",
      "            The converged solution.\n",
      "        info : int\n",
      "            Provides convergence information:\n",
      "              * 0  : successful exit\n",
      "              * >0 : convergence to tolerance not achieved, number of iterations\n",
      "              * <0 : illegal input or breakdown\n",
      "        \n",
      "        Other parameters\n",
      "        ----------------\n",
      "        x0 : {array, matrix}\n",
      "            Starting guess for the solution (a vector of zeros by default).\n",
      "        tol : float\n",
      "            Tolerance to achieve. The algorithm terminates when either the relative\n",
      "            or the absolute residual is below `tol`.\n",
      "        restart : int, optional\n",
      "            Number of iterations between restarts. Larger values increase\n",
      "            iteration cost, but may be necessary for convergence.\n",
      "            Default is 20.\n",
      "        maxiter : int, optional\n",
      "            Maximum number of iterations (restart cycles).  Iteration will stop\n",
      "            after maxiter steps even if the specified tolerance has not been\n",
      "            achieved.\n",
      "        M : {sparse matrix, dense matrix, LinearOperator}\n",
      "            Inverse of the preconditioner of A.  M should approximate the\n",
      "            inverse of A and be easy to solve for (see Notes).  Effective\n",
      "            preconditioning dramatically improves the rate of convergence,\n",
      "            which implies that fewer iterations are needed to reach a given\n",
      "            error tolerance.  By default, no preconditioner is used.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(rk), where rk is the current residual vector.\n",
      "        restrt : int, optional\n",
      "            DEPRECATED - use `restart` instead.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        LinearOperator\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        A preconditioner, P, is chosen such that P is close to A but easy to solve\n",
      "        for. The preconditioner parameter required by this routine is\n",
      "        ``M = P^-1``. The inverse should preferably not be calculated\n",
      "        explicitly.  Rather, use the following template to produce M::\n",
      "        \n",
      "          # Construct a linear operator that computes P^-1 * x.\n",
      "          import scipy.sparse.linalg as spla\n",
      "          M_x = lambda x: spla.spsolve(P, x)\n",
      "          M = spla.LinearOperator((n, n), M_x)\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import gmres\n",
      "        >>> A = csc_matrix([[3, 2, 0], [1, -1, 0], [0, 5, 1]], dtype=float)\n",
      "        >>> b = np.array([2, 4, -1], dtype=float)\n",
      "        >>> x, exitCode = gmres(A, b)\n",
      "        >>> print(exitCode)            # 0 indicates successful convergence\n",
      "        0\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "    \n",
      "    inv(A)\n",
      "        Compute the inverse of a sparse matrix\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : (M,M) ndarray or sparse matrix\n",
      "            square matrix to be inverted\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Ainv : (M,M) ndarray or sparse matrix\n",
      "            inverse of `A`\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This computes the sparse inverse of `A`.  If the inverse of `A` is expected\n",
      "        to be non-sparse, it will likely be faster to convert `A` to dense and use\n",
      "        scipy.linalg.inv.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import inv\n",
      "        >>> A = csc_matrix([[1., 0.], [1., 2.]])\n",
      "        >>> Ainv = inv(A)\n",
      "        >>> Ainv\n",
      "        <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "            with 3 stored elements in Compressed Sparse Column format>\n",
      "        >>> A.dot(Ainv)\n",
      "        <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "            with 2 stored elements in Compressed Sparse Column format>\n",
      "        >>> A.dot(Ainv).todense()\n",
      "        matrix([[ 1.,  0.],\n",
      "                [ 0.,  1.]])\n",
      "        \n",
      "        .. versionadded:: 0.12.0\n",
      "    \n",
      "    lgmres(A, b, x0=None, tol=1e-05, maxiter=1000, M=None, callback=None, inner_m=30, outer_k=3, outer_v=None, store_outer_Av=True, prepend_outer_v=False)\n",
      "        Solve a matrix equation using the LGMRES algorithm.\n",
      "        \n",
      "        The LGMRES algorithm [1]_ [2]_ is designed to avoid some problems\n",
      "        in the convergence in restarted GMRES, and often converges in fewer\n",
      "        iterations.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, dense matrix, LinearOperator}\n",
      "            The real or complex N-by-N matrix of the linear system.\n",
      "        b : {array, matrix}\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        x0  : {array, matrix}\n",
      "            Starting guess for the solution.\n",
      "        tol : float, optional\n",
      "            Tolerance to achieve. The algorithm terminates when either the relative\n",
      "            or the absolute residual is below `tol`.\n",
      "        maxiter : int, optional\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, dense matrix, LinearOperator}, optional\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A.  Effective preconditioning dramatically improves the\n",
      "            rate of convergence, which implies that fewer iterations are needed\n",
      "            to reach a given error tolerance.\n",
      "        callback : function, optional\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "        inner_m : int, optional\n",
      "            Number of inner GMRES iterations per each outer iteration.\n",
      "        outer_k : int, optional\n",
      "            Number of vectors to carry between inner GMRES iterations.\n",
      "            According to [1]_, good values are in the range of 1...3.\n",
      "            However, note that if you want to use the additional vectors to\n",
      "            accelerate solving multiple similar problems, larger values may\n",
      "            be beneficial.\n",
      "        outer_v : list of tuples, optional\n",
      "            List containing tuples ``(v, Av)`` of vectors and corresponding\n",
      "            matrix-vector products, used to augment the Krylov subspace, and\n",
      "            carried between inner GMRES iterations. The element ``Av`` can\n",
      "            be `None` if the matrix-vector product should be re-evaluated.\n",
      "            This parameter is modified in-place by `lgmres`, and can be used\n",
      "            to pass \"guess\" vectors in and out of the algorithm when solving\n",
      "            similar problems.\n",
      "        store_outer_Av : bool, optional\n",
      "            Whether LGMRES should store also A*v in addition to vectors `v`\n",
      "            in the `outer_v` list. Default is True.\n",
      "        prepend_outer_v : bool, optional \n",
      "            Whether to put outer_v augmentation vectors before Krylov iterates.\n",
      "            In standard LGMRES, prepend_outer_v=False.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : array or matrix\n",
      "            The converged solution.\n",
      "        info : int\n",
      "            Provides convergence information:\n",
      "        \n",
      "                - 0  : successful exit\n",
      "                - >0 : convergence to tolerance not achieved, number of iterations\n",
      "                - <0 : illegal input or breakdown\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The LGMRES algorithm [1]_ [2]_ is designed to avoid the\n",
      "        slowing of convergence in restarted GMRES, due to alternating\n",
      "        residual vectors. Typically, it often outperforms GMRES(m) of\n",
      "        comparable memory requirements by some measure, or at least is not\n",
      "        much worse.\n",
      "        \n",
      "        Another advantage in this algorithm is that you can supply it with\n",
      "        'guess' vectors in the `outer_v` argument that augment the Krylov\n",
      "        subspace. If the solution lies close to the span of these vectors,\n",
      "        the algorithm converges faster. This can be useful if several very\n",
      "        similar matrices need to be inverted one after another, such as in\n",
      "        Newton-Krylov iteration where the Jacobian matrix often changes\n",
      "        little in the nonlinear steps.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] A.H. Baker and E.R. Jessup and T. Manteuffel, \"A Technique for\n",
      "                 Accelerating the Convergence of Restarted GMRES\", SIAM J. Matrix\n",
      "                 Anal. Appl. 26, 962 (2005).\n",
      "        .. [2] A.H. Baker, \"On Improving the Performance of the Linear Solver\n",
      "                 restarted GMRES\", PhD thesis, University of Colorado (2003).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import lgmres\n",
      "        >>> A = csc_matrix([[3, 2, 0], [1, -1, 0], [0, 5, 1]], dtype=float)\n",
      "        >>> b = np.array([2, 4, -1], dtype=float)\n",
      "        >>> x, exitCode = lgmres(A, b)\n",
      "        >>> print(exitCode)            # 0 indicates successful convergence\n",
      "        0\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "    \n",
      "    lobpcg(A, X, B=None, M=None, Y=None, tol=None, maxiter=20, largest=True, verbosityLevel=0, retLambdaHistory=False, retResidualNormsHistory=False)\n",
      "        Locally Optimal Block Preconditioned Conjugate Gradient Method (LOBPCG)\n",
      "        \n",
      "        LOBPCG is a preconditioned eigensolver for large symmetric positive\n",
      "        definite (SPD) generalized eigenproblems.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, dense matrix, LinearOperator}\n",
      "            The symmetric linear operator of the problem, usually a\n",
      "            sparse matrix.  Often called the \"stiffness matrix\".\n",
      "        X : array_like\n",
      "            Initial approximation to the k eigenvectors. If A has\n",
      "            shape=(n,n) then X should have shape shape=(n,k).\n",
      "        B : {dense matrix, sparse matrix, LinearOperator}, optional\n",
      "            the right hand side operator in a generalized eigenproblem.\n",
      "            by default, B = Identity\n",
      "            often called the \"mass matrix\"\n",
      "        M : {dense matrix, sparse matrix, LinearOperator}, optional\n",
      "            preconditioner to A; by default M = Identity\n",
      "            M should approximate the inverse of A\n",
      "        Y : array_like, optional\n",
      "            n-by-sizeY matrix of constraints, sizeY < n\n",
      "            The iterations will be performed in the B-orthogonal complement\n",
      "            of the column-space of Y. Y must be full rank.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : array\n",
      "            Array of k eigenvalues\n",
      "        v : array\n",
      "            An array of k eigenvectors.  V has the same shape as X.\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        tol : scalar, optional\n",
      "            Solver tolerance (stopping criterion)\n",
      "            by default: tol=n*sqrt(eps)\n",
      "        maxiter : integer, optional\n",
      "            maximum number of iterations\n",
      "            by default: maxiter=min(n,20)\n",
      "        largest : bool, optional\n",
      "            when True, solve for the largest eigenvalues, otherwise the smallest\n",
      "        verbosityLevel : integer, optional\n",
      "            controls solver output.  default: verbosityLevel = 0.\n",
      "        retLambdaHistory : boolean, optional\n",
      "            whether to return eigenvalue history\n",
      "        retResidualNormsHistory : boolean, optional\n",
      "            whether to return history of residual norms\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        Solve A x = lambda B x with constraints and preconditioning.\n",
      "        \n",
      "        >>> from scipy.sparse import spdiags, issparse\n",
      "        >>> from scipy.sparse.linalg import lobpcg, LinearOperator\n",
      "        >>> n = 100\n",
      "        >>> vals = [np.arange(n, dtype=np.float64) + 1]\n",
      "        >>> A = spdiags(vals, 0, n, n)\n",
      "        >>> A.toarray()\n",
      "        array([[   1.,    0.,    0., ...,    0.,    0.,    0.],\n",
      "               [   0.,    2.,    0., ...,    0.,    0.,    0.],\n",
      "               [   0.,    0.,    3., ...,    0.,    0.,    0.],\n",
      "               ...,\n",
      "               [   0.,    0.,    0., ...,   98.,    0.,    0.],\n",
      "               [   0.,    0.,    0., ...,    0.,   99.,    0.],\n",
      "               [   0.,    0.,    0., ...,    0.,    0.,  100.]])\n",
      "        \n",
      "        Constraints.\n",
      "        \n",
      "        >>> Y = np.eye(n, 3)\n",
      "        \n",
      "        Initial guess for eigenvectors, should have linearly independent\n",
      "        columns. Column dimension = number of requested eigenvalues.\n",
      "        \n",
      "        >>> X = np.random.rand(n, 3)\n",
      "        \n",
      "        Preconditioner -- inverse of A (as an abstract linear operator).\n",
      "        \n",
      "        >>> invA = spdiags([1./vals[0]], 0, n, n)\n",
      "        >>> def precond( x ):\n",
      "        ...     return invA  * x\n",
      "        >>> M = LinearOperator(matvec=precond, shape=(n, n), dtype=float)\n",
      "        \n",
      "        Here, ``invA`` could of course have been used directly as a preconditioner.\n",
      "        Let us then solve the problem:\n",
      "        \n",
      "        >>> eigs, vecs = lobpcg(A, X, Y=Y, M=M, tol=1e-4, maxiter=40, largest=False)\n",
      "        >>> eigs\n",
      "        array([ 4.,  5.,  6.])\n",
      "        \n",
      "        Note that the vectors passed in Y are the eigenvectors of the 3 smallest\n",
      "        eigenvalues. The results returned are orthogonal to those.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        If both retLambdaHistory and retResidualNormsHistory are True,\n",
      "        the return tuple has the following format\n",
      "        (lambda, V, lambda history, residual norms history).\n",
      "        \n",
      "        In the following ``n`` denotes the matrix size and ``m`` the number\n",
      "        of required eigenvalues (smallest or largest).\n",
      "        \n",
      "        The LOBPCG code internally solves eigenproblems of the size 3``m`` on every\n",
      "        iteration by calling the \"standard\" dense eigensolver, so if ``m`` is not\n",
      "        small enough compared to ``n``, it does not make sense to call the LOBPCG\n",
      "        code, but rather one should use the \"standard\" eigensolver,\n",
      "        e.g. numpy or scipy function in this case.\n",
      "        If one calls the LOBPCG algorithm for 5``m``>``n``,\n",
      "        it will most likely break internally, so the code tries to call the standard\n",
      "        function instead.\n",
      "        \n",
      "        It is not that n should be large for the LOBPCG to work, but rather the\n",
      "        ratio ``n``/``m`` should be large. It you call the LOBPCG code with ``m``=1\n",
      "        and ``n``=10, it should work, though ``n`` is small. The method is intended\n",
      "        for extremely large ``n``/``m``, see e.g., reference [28] in\n",
      "        http://arxiv.org/abs/0705.2626\n",
      "        \n",
      "        The convergence speed depends basically on two factors:\n",
      "        \n",
      "        1.  How well relatively separated the seeking eigenvalues are\n",
      "            from the rest of the eigenvalues.\n",
      "            One can try to vary ``m`` to make this better.\n",
      "        \n",
      "        2.  How well conditioned the problem is. This can be changed by using proper\n",
      "            preconditioning. For example, a rod vibration test problem (under tests\n",
      "            directory) is ill-conditioned for large ``n``, so convergence will be\n",
      "            slow, unless efficient preconditioning is used.\n",
      "            For this specific problem, a good simple preconditioner function would\n",
      "            be a linear solve for A, which is easy to code since A is tridiagonal.\n",
      "        \n",
      "        *Acknowledgements*\n",
      "        \n",
      "        lobpcg.py code was written by Robert Cimrman.\n",
      "        Many thanks belong to Andrew Knyazev, the author of the algorithm,\n",
      "        for lots of advice and support.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] A. V. Knyazev (2001),\n",
      "               Toward the Optimal Preconditioned Eigensolver: Locally Optimal\n",
      "               Block Preconditioned Conjugate Gradient Method.\n",
      "               SIAM Journal on Scientific Computing 23, no. 2,\n",
      "               pp. 517-541. http://dx.doi.org/10.1137/S1064827500366124\n",
      "        \n",
      "        .. [2] A. V. Knyazev, I. Lashuk, M. E. Argentati, and E. Ovchinnikov (2007),\n",
      "               Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX)\n",
      "               in hypre and PETSc.  http://arxiv.org/abs/0705.2626\n",
      "        \n",
      "        .. [3] A. V. Knyazev's C and MATLAB implementations:\n",
      "               https://bitbucket.org/joseroman/blopex\n",
      "    \n",
      "    lsmr(A, b, damp=0.0, atol=1e-06, btol=1e-06, conlim=100000000.0, maxiter=None, show=False, x0=None)\n",
      "        Iterative solver for least-squares problems.\n",
      "        \n",
      "        lsmr solves the system of linear equations ``Ax = b``. If the system\n",
      "        is inconsistent, it solves the least-squares problem ``min ||b - Ax||_2``.\n",
      "        A is a rectangular matrix of dimension m-by-n, where all cases are\n",
      "        allowed: m = n, m > n, or m < n. B is a vector of length m.\n",
      "        The matrix A may be dense or sparse (usually sparse).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {matrix, sparse matrix, ndarray, LinearOperator}\n",
      "            Matrix A in the linear system.\n",
      "        b : array_like, shape (m,)\n",
      "            Vector b in the linear system.\n",
      "        damp : float\n",
      "            Damping factor for regularized least-squares. `lsmr` solves\n",
      "            the regularized least-squares problem::\n",
      "        \n",
      "             min ||(b) - (  A   )x||\n",
      "                 ||(0)   (damp*I) ||_2\n",
      "        \n",
      "            where damp is a scalar.  If damp is None or 0, the system\n",
      "            is solved without regularization.\n",
      "        atol, btol : float, optional\n",
      "            Stopping tolerances. `lsmr` continues iterations until a\n",
      "            certain backward error estimate is smaller than some quantity\n",
      "            depending on atol and btol.  Let ``r = b - Ax`` be the\n",
      "            residual vector for the current approximate solution ``x``.\n",
      "            If ``Ax = b`` seems to be consistent, ``lsmr`` terminates\n",
      "            when ``norm(r) <= atol * norm(A) * norm(x) + btol * norm(b)``.\n",
      "            Otherwise, lsmr terminates when ``norm(A^{T} r) <=\n",
      "            atol * norm(A) * norm(r)``.  If both tolerances are 1.0e-6 (say),\n",
      "            the final ``norm(r)`` should be accurate to about 6\n",
      "            digits. (The final x will usually have fewer correct digits,\n",
      "            depending on ``cond(A)`` and the size of LAMBDA.)  If `atol`\n",
      "            or `btol` is None, a default value of 1.0e-6 will be used.\n",
      "            Ideally, they should be estimates of the relative error in the\n",
      "            entries of A and B respectively.  For example, if the entries\n",
      "            of `A` have 7 correct digits, set atol = 1e-7. This prevents\n",
      "            the algorithm from doing unnecessary work beyond the\n",
      "            uncertainty of the input data.\n",
      "        conlim : float, optional\n",
      "            `lsmr` terminates if an estimate of ``cond(A)`` exceeds\n",
      "            `conlim`.  For compatible systems ``Ax = b``, conlim could be\n",
      "            as large as 1.0e+12 (say).  For least-squares problems,\n",
      "            `conlim` should be less than 1.0e+8. If `conlim` is None, the\n",
      "            default value is 1e+8.  Maximum precision can be obtained by\n",
      "            setting ``atol = btol = conlim = 0``, but the number of\n",
      "            iterations may then be excessive.\n",
      "        maxiter : int, optional\n",
      "            `lsmr` terminates if the number of iterations reaches\n",
      "            `maxiter`.  The default is ``maxiter = min(m, n)``.  For\n",
      "            ill-conditioned systems, a larger value of `maxiter` may be\n",
      "            needed.\n",
      "        show : bool, optional\n",
      "            Print iterations logs if ``show=True``.\n",
      "        x0 : array_like, shape (n,), optional\n",
      "            Initial guess of x, if None zeros are used.\n",
      "        \n",
      "            .. versionadded:: 1.0.0\n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray of float\n",
      "            Least-square solution returned.\n",
      "        istop : int\n",
      "            istop gives the reason for stopping::\n",
      "        \n",
      "              istop   = 0 means x=0 is a solution.  If x0 was given, then x=x0 is a\n",
      "                          solution.\n",
      "                      = 1 means x is an approximate solution to A*x = B,\n",
      "                          according to atol and btol.\n",
      "                      = 2 means x approximately solves the least-squares problem\n",
      "                          according to atol.\n",
      "                      = 3 means COND(A) seems to be greater than CONLIM.\n",
      "                      = 4 is the same as 1 with atol = btol = eps (machine\n",
      "                          precision)\n",
      "                      = 5 is the same as 2 with atol = eps.\n",
      "                      = 6 is the same as 3 with CONLIM = 1/eps.\n",
      "                      = 7 means ITN reached maxiter before the other stopping\n",
      "                          conditions were satisfied.\n",
      "        \n",
      "        itn : int\n",
      "            Number of iterations used.\n",
      "        normr : float\n",
      "            ``norm(b-Ax)``\n",
      "        normar : float\n",
      "            ``norm(A^T (b - Ax))``\n",
      "        norma : float\n",
      "            ``norm(A)``\n",
      "        conda : float\n",
      "            Condition number of A.\n",
      "        normx : float\n",
      "            ``norm(x)``\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 0.11.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] D. C.-L. Fong and M. A. Saunders,\n",
      "               \"LSMR: An iterative algorithm for sparse least-squares problems\",\n",
      "               SIAM J. Sci. Comput., vol. 33, pp. 2950-2971, 2011.\n",
      "               http://arxiv.org/abs/1006.0758\n",
      "        .. [2] LSMR Software, http://web.stanford.edu/group/SOL/software/lsmr/\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import lsmr\n",
      "        >>> A = csc_matrix([[1., 0.], [1., 1.], [0., 1.]], dtype=float)\n",
      "        \n",
      "        The first example has the trivial solution `[0, 0]`\n",
      "        \n",
      "        >>> b = np.array([0., 0., 0.], dtype=float)\n",
      "        >>> x, istop, itn, normr = lsmr(A, b)[:4]\n",
      "        >>> istop\n",
      "        0\n",
      "        >>> x\n",
      "        array([ 0.,  0.])\n",
      "        \n",
      "        The stopping code `istop=0` returned indicates that a vector of zeros was\n",
      "        found as a solution. The returned solution `x` indeed contains `[0., 0.]`.\n",
      "        The next example has a non-trivial solution:\n",
      "        \n",
      "        >>> b = np.array([1., 0., -1.], dtype=float)\n",
      "        >>> x, istop, itn, normr = lsmr(A, b)[:4]\n",
      "        >>> istop\n",
      "        1\n",
      "        >>> x\n",
      "        array([ 1., -1.])\n",
      "        >>> itn\n",
      "        1\n",
      "        >>> normr\n",
      "        4.440892098500627e-16\n",
      "        \n",
      "        As indicated by `istop=1`, `lsmr` found a solution obeying the tolerance\n",
      "        limits. The given solution `[1., -1.]` obviously solves the equation. The\n",
      "        remaining return values include information about the number of iterations\n",
      "        (`itn=1`) and the remaining difference of left and right side of the solved\n",
      "        equation.\n",
      "        The final example demonstrates the behavior in the case where there is no\n",
      "        solution for the equation:\n",
      "        \n",
      "        >>> b = np.array([1., 0.01, -1.], dtype=float)\n",
      "        >>> x, istop, itn, normr = lsmr(A, b)[:4]\n",
      "        >>> istop\n",
      "        2\n",
      "        >>> x\n",
      "        array([ 1.00333333, -0.99666667])\n",
      "        >>> A.dot(x)-b\n",
      "        array([ 0.00333333, -0.00333333,  0.00333333])\n",
      "        >>> normr\n",
      "        0.005773502691896255\n",
      "        \n",
      "        `istop` indicates that the system is inconsistent and thus `x` is rather an\n",
      "        approximate solution to the corresponding least-squares problem. `normr`\n",
      "        contains the minimal distance that was found.\n",
      "    \n",
      "    lsqr(A, b, damp=0.0, atol=1e-08, btol=1e-08, conlim=100000000.0, iter_lim=None, show=False, calc_var=False, x0=None)\n",
      "        Find the least-squares solution to a large, sparse, linear system\n",
      "        of equations.\n",
      "        \n",
      "        The function solves ``Ax = b``  or  ``min ||b - Ax||^2`` or\n",
      "        ``min ||Ax - b||^2 + d^2 ||x||^2``.\n",
      "        \n",
      "        The matrix A may be square or rectangular (over-determined or\n",
      "        under-determined), and may have any rank.\n",
      "        \n",
      "        ::\n",
      "        \n",
      "          1. Unsymmetric equations --    solve  A*x = b\n",
      "        \n",
      "          2. Linear least squares  --    solve  A*x = b\n",
      "                                         in the least-squares sense\n",
      "        \n",
      "          3. Damped least squares  --    solve  (   A    )*x = ( b )\n",
      "                                                ( damp*I )     ( 0 )\n",
      "                                         in the least-squares sense\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, ndarray, LinearOperator}\n",
      "            Representation of an m-by-n matrix.  It is required that\n",
      "            the linear operator can produce ``Ax`` and ``A^T x``.\n",
      "        b : array_like, shape (m,)\n",
      "            Right-hand side vector ``b``.\n",
      "        damp : float\n",
      "            Damping coefficient.\n",
      "        atol, btol : float, optional\n",
      "            Stopping tolerances. If both are 1.0e-9 (say), the final\n",
      "            residual norm should be accurate to about 9 digits.  (The\n",
      "            final x will usually have fewer correct digits, depending on\n",
      "            cond(A) and the size of damp.)\n",
      "        conlim : float, optional\n",
      "            Another stopping tolerance.  lsqr terminates if an estimate of\n",
      "            ``cond(A)`` exceeds `conlim`.  For compatible systems ``Ax =\n",
      "            b``, `conlim` could be as large as 1.0e+12 (say).  For\n",
      "            least-squares problems, conlim should be less than 1.0e+8.\n",
      "            Maximum precision can be obtained by setting ``atol = btol =\n",
      "            conlim = zero``, but the number of iterations may then be\n",
      "            excessive.\n",
      "        iter_lim : int, optional\n",
      "            Explicit limitation on number of iterations (for safety).\n",
      "        show : bool, optional\n",
      "            Display an iteration log.\n",
      "        calc_var : bool, optional\n",
      "            Whether to estimate diagonals of ``(A'A + damp^2*I)^{-1}``.\n",
      "        x0 : array_like, shape (n,), optional\n",
      "            Initial guess of x, if None zeros are used.\n",
      "        \n",
      "            .. versionadded:: 1.0.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray of float\n",
      "            The final solution.\n",
      "        istop : int\n",
      "            Gives the reason for termination.\n",
      "            1 means x is an approximate solution to Ax = b.\n",
      "            2 means x approximately solves the least-squares problem.\n",
      "        itn : int\n",
      "            Iteration number upon termination.\n",
      "        r1norm : float\n",
      "            ``norm(r)``, where ``r = b - Ax``.\n",
      "        r2norm : float\n",
      "            ``sqrt( norm(r)^2  +  damp^2 * norm(x)^2 )``.  Equal to `r1norm` if\n",
      "            ``damp == 0``.\n",
      "        anorm : float\n",
      "            Estimate of Frobenius norm of ``Abar = [[A]; [damp*I]]``.\n",
      "        acond : float\n",
      "            Estimate of ``cond(Abar)``.\n",
      "        arnorm : float\n",
      "            Estimate of ``norm(A'*r - damp^2*x)``.\n",
      "        xnorm : float\n",
      "            ``norm(x)``\n",
      "        var : ndarray of float\n",
      "            If ``calc_var`` is True, estimates all diagonals of\n",
      "            ``(A'A)^{-1}`` (if ``damp == 0``) or more generally ``(A'A +\n",
      "            damp^2*I)^{-1}``.  This is well defined if A has full column\n",
      "            rank or ``damp > 0``.  (Not sure what var means if ``rank(A)\n",
      "            < n`` and ``damp = 0.``)\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        LSQR uses an iterative method to approximate the solution.  The\n",
      "        number of iterations required to reach a certain accuracy depends\n",
      "        strongly on the scaling of the problem.  Poor scaling of the rows\n",
      "        or columns of A should therefore be avoided where possible.\n",
      "        \n",
      "        For example, in problem 1 the solution is unaltered by\n",
      "        row-scaling.  If a row of A is very small or large compared to\n",
      "        the other rows of A, the corresponding row of ( A  b ) should be\n",
      "        scaled up or down.\n",
      "        \n",
      "        In problems 1 and 2, the solution x is easily recovered\n",
      "        following column-scaling.  Unless better information is known,\n",
      "        the nonzero columns of A should be scaled so that they all have\n",
      "        the same Euclidean norm (e.g., 1.0).\n",
      "        \n",
      "        In problem 3, there is no freedom to re-scale if damp is\n",
      "        nonzero.  However, the value of damp should be assigned only\n",
      "        after attention has been paid to the scaling of A.\n",
      "        \n",
      "        The parameter damp is intended to help regularize\n",
      "        ill-conditioned systems, by preventing the true solution from\n",
      "        being very large.  Another aid to regularization is provided by\n",
      "        the parameter acond, which may be used to terminate iterations\n",
      "        before the computed solution becomes very large.\n",
      "        \n",
      "        If some initial estimate ``x0`` is known and if ``damp == 0``,\n",
      "        one could proceed as follows:\n",
      "        \n",
      "          1. Compute a residual vector ``r0 = b - A*x0``.\n",
      "          2. Use LSQR to solve the system  ``A*dx = r0``.\n",
      "          3. Add the correction dx to obtain a final solution ``x = x0 + dx``.\n",
      "        \n",
      "        This requires that ``x0`` be available before and after the call\n",
      "        to LSQR.  To judge the benefits, suppose LSQR takes k1 iterations\n",
      "        to solve A*x = b and k2 iterations to solve A*dx = r0.\n",
      "        If x0 is \"good\", norm(r0) will be smaller than norm(b).\n",
      "        If the same stopping tolerances atol and btol are used for each\n",
      "        system, k1 and k2 will be similar, but the final solution x0 + dx\n",
      "        should be more accurate.  The only way to reduce the total work\n",
      "        is to use a larger stopping tolerance for the second system.\n",
      "        If some value btol is suitable for A*x = b, the larger value\n",
      "        btol*norm(b)/norm(r0)  should be suitable for A*dx = r0.\n",
      "        \n",
      "        Preconditioning is another way to reduce the number of iterations.\n",
      "        If it is possible to solve a related system ``M*x = b``\n",
      "        efficiently, where M approximates A in some helpful way (e.g. M -\n",
      "        A has low rank or its elements are small relative to those of A),\n",
      "        LSQR may converge more rapidly on the system ``A*M(inverse)*z =\n",
      "        b``, after which x can be recovered by solving M*x = z.\n",
      "        \n",
      "        If A is symmetric, LSQR should not be used!\n",
      "        \n",
      "        Alternatives are the symmetric conjugate-gradient method (cg)\n",
      "        and/or SYMMLQ.  SYMMLQ is an implementation of symmetric cg that\n",
      "        applies to any symmetric A and will converge more rapidly than\n",
      "        LSQR.  If A is positive definite, there are other implementations\n",
      "        of symmetric cg that require slightly less work per iteration than\n",
      "        SYMMLQ (but will take the same number of iterations).\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] C. C. Paige and M. A. Saunders (1982a).\n",
      "               \"LSQR: An algorithm for sparse linear equations and\n",
      "               sparse least squares\", ACM TOMS 8(1), 43-71.\n",
      "        .. [2] C. C. Paige and M. A. Saunders (1982b).\n",
      "               \"Algorithm 583.  LSQR: Sparse linear equations and least\n",
      "               squares problems\", ACM TOMS 8(2), 195-209.\n",
      "        .. [3] M. A. Saunders (1995).  \"Solution of sparse rectangular\n",
      "               systems using LSQR and CRAIG\", BIT 35, 588-604.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import lsqr\n",
      "        >>> A = csc_matrix([[1., 0.], [1., 1.], [0., 1.]], dtype=float)\n",
      "        \n",
      "        The first example has the trivial solution `[0, 0]`\n",
      "        \n",
      "        >>> b = np.array([0., 0., 0.], dtype=float)\n",
      "        >>> x, istop, itn, normr = lsqr(A, b)[:4]\n",
      "        The exact solution is  x = 0\n",
      "        >>> istop\n",
      "        0\n",
      "        >>> x\n",
      "        array([ 0.,  0.])\n",
      "        \n",
      "        The stopping code `istop=0` returned indicates that a vector of zeros was\n",
      "        found as a solution. The returned solution `x` indeed contains `[0., 0.]`.\n",
      "        The next example has a non-trivial solution:\n",
      "        \n",
      "        >>> b = np.array([1., 0., -1.], dtype=float)\n",
      "        >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\n",
      "        >>> istop\n",
      "        1\n",
      "        >>> x\n",
      "        array([ 1., -1.])\n",
      "        >>> itn\n",
      "        1\n",
      "        >>> r1norm\n",
      "        4.440892098500627e-16\n",
      "        \n",
      "        As indicated by `istop=1`, `lsqr` found a solution obeying the tolerance\n",
      "        limits. The given solution `[1., -1.]` obviously solves the equation. The\n",
      "        remaining return values include information about the number of iterations\n",
      "        (`itn=1`) and the remaining difference of left and right side of the solved\n",
      "        equation.\n",
      "        The final example demonstrates the behavior in the case where there is no\n",
      "        solution for the equation:\n",
      "        \n",
      "        >>> b = np.array([1., 0.01, -1.], dtype=float)\n",
      "        >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\n",
      "        >>> istop\n",
      "        2\n",
      "        >>> x\n",
      "        array([ 1.00333333, -0.99666667])\n",
      "        >>> A.dot(x)-b\n",
      "        array([ 0.00333333, -0.00333333,  0.00333333])\n",
      "        >>> r1norm\n",
      "        0.005773502691896255\n",
      "        \n",
      "        `istop` indicates that the system is inconsistent and thus `x` is rather an\n",
      "        approximate solution to the corresponding least-squares problem. `r1norm`\n",
      "        contains the norm of the minimal residual that was found.\n",
      "    \n",
      "    minres(A, b, x0=None, shift=0.0, tol=1e-05, maxiter=None, M=None, callback=None, show=False, check=False)\n",
      "        Use MINimum RESidual iteration to solve Ax=b\n",
      "        \n",
      "        MINRES minimizes norm(A*x - b) for a real symmetric matrix A.  Unlike\n",
      "        the Conjugate Gradient method, A can be indefinite or singular.\n",
      "        \n",
      "        If shift != 0 then the method solves (A - shift*I)x = b\n",
      "        \n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, dense matrix, LinearOperator}\n",
      "            The real symmetric N-by-N matrix of the linear system\n",
      "        b : {array, matrix}\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : {array, matrix}\n",
      "            The converged solution.\n",
      "        info : integer\n",
      "            Provides convergence information:\n",
      "                0  : successful exit\n",
      "                >0 : convergence to tolerance not achieved, number of iterations\n",
      "                <0 : illegal input or breakdown\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        x0  : {array, matrix}\n",
      "            Starting guess for the solution.\n",
      "        tol : float\n",
      "            Tolerance to achieve. The algorithm terminates when either the relative\n",
      "            or the absolute residual is below `tol`.\n",
      "        maxiter : integer\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, dense matrix, LinearOperator}\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A.  Effective preconditioning dramatically improves the\n",
      "            rate of convergence, which implies that fewer iterations are needed\n",
      "            to reach a given error tolerance.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        THIS FUNCTION IS EXPERIMENTAL AND SUBJECT TO CHANGE!\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        Solution of sparse indefinite systems of linear equations,\n",
      "            C. C. Paige and M. A. Saunders (1975),\n",
      "            SIAM J. Numer. Anal. 12(4), pp. 617-629.\n",
      "            https://web.stanford.edu/group/SOL/software/minres/\n",
      "        \n",
      "        This file is a translation of the following MATLAB implementation:\n",
      "            https://web.stanford.edu/group/SOL/software/minres/minres-matlab.zip\n",
      "    \n",
      "    norm(x, ord=None, axis=None)\n",
      "        Norm of a sparse matrix\n",
      "        \n",
      "        This function is able to return one of seven different matrix norms,\n",
      "        depending on the value of the ``ord`` parameter.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : a sparse matrix\n",
      "            Input sparse matrix.\n",
      "        ord : {non-zero int, inf, -inf, 'fro'}, optional\n",
      "            Order of the norm (see table under ``Notes``). inf means numpy's\n",
      "            `inf` object.\n",
      "        axis : {int, 2-tuple of ints, None}, optional\n",
      "            If `axis` is an integer, it specifies the axis of `x` along which to\n",
      "            compute the vector norms.  If `axis` is a 2-tuple, it specifies the\n",
      "            axes that hold 2-D matrices, and the matrix norms of these matrices\n",
      "            are computed.  If `axis` is None then either a vector norm (when `x`\n",
      "            is 1-D) or a matrix norm (when `x` is 2-D) is returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        n : float or ndarray\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Some of the ord are not implemented because some associated functions like, \n",
      "        _multi_svd_norm, are not yet available for sparse matrix. \n",
      "        \n",
      "        This docstring is modified based on numpy.linalg.norm. \n",
      "        https://github.com/numpy/numpy/blob/master/numpy/linalg/linalg.py \n",
      "        \n",
      "        The following norms can be calculated:\n",
      "        \n",
      "        =====  ============================  \n",
      "        ord    norm for sparse matrices             \n",
      "        =====  ============================  \n",
      "        None   Frobenius norm                \n",
      "        'fro'  Frobenius norm                \n",
      "        inf    max(sum(abs(x), axis=1))      \n",
      "        -inf   min(sum(abs(x), axis=1))      \n",
      "        0      abs(x).sum(axis=axis)                           \n",
      "        1      max(sum(abs(x), axis=0))      \n",
      "        -1     min(sum(abs(x), axis=0))      \n",
      "        2      Not implemented  \n",
      "        -2     Not implemented      \n",
      "        other  Not implemented                               \n",
      "        =====  ============================  \n",
      "        \n",
      "        The Frobenius norm is given by [1]_:\n",
      "        \n",
      "            :math:`||A||_F = [\\sum_{i,j} abs(a_{i,j})^2]^{1/2}`\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. H. Golub and C. F. Van Loan, *Matrix Computations*,\n",
      "            Baltimore, MD, Johns Hopkins University Press, 1985, pg. 15\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import *\n",
      "        >>> import numpy as np\n",
      "        >>> from scipy.sparse.linalg import norm\n",
      "        >>> a = np.arange(9) - 4\n",
      "        >>> a\n",
      "        array([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
      "        >>> b = a.reshape((3, 3))\n",
      "        >>> b\n",
      "        array([[-4, -3, -2],\n",
      "               [-1, 0, 1],\n",
      "               [ 2, 3, 4]])\n",
      "        \n",
      "        >>> b = csr_matrix(b)\n",
      "        >>> norm(b)\n",
      "        7.745966692414834\n",
      "        >>> norm(b, 'fro')\n",
      "        7.745966692414834\n",
      "        >>> norm(b, np.inf)\n",
      "        9\n",
      "        >>> norm(b, -np.inf)\n",
      "        2\n",
      "        >>> norm(b, 1)\n",
      "        7\n",
      "        >>> norm(b, -1)\n",
      "        6\n",
      "    \n",
      "    onenormest(A, t=2, itmax=5, compute_v=False, compute_w=False)\n",
      "        Compute a lower bound of the 1-norm of a sparse matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : ndarray or other linear operator\n",
      "            A linear operator that can be transposed and that can\n",
      "            produce matrix products.\n",
      "        t : int, optional\n",
      "            A positive parameter controlling the tradeoff between\n",
      "            accuracy versus time and memory usage.\n",
      "            Larger values take longer and use more memory\n",
      "            but give more accurate output.\n",
      "        itmax : int, optional\n",
      "            Use at most this many iterations.\n",
      "        compute_v : bool, optional\n",
      "            Request a norm-maximizing linear operator input vector if True.\n",
      "        compute_w : bool, optional\n",
      "            Request a norm-maximizing linear operator output vector if True.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        est : float\n",
      "            An underestimate of the 1-norm of the sparse matrix.\n",
      "        v : ndarray, optional\n",
      "            The vector such that ||Av||_1 == est*||v||_1.\n",
      "            It can be thought of as an input to the linear operator\n",
      "            that gives an output with particularly large norm.\n",
      "        w : ndarray, optional\n",
      "            The vector Av which has relatively large 1-norm.\n",
      "            It can be thought of as an output of the linear operator\n",
      "            that is relatively large in norm compared to the input.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is algorithm 2.4 of [1].\n",
      "        \n",
      "        In [2] it is described as follows.\n",
      "        \"This algorithm typically requires the evaluation of\n",
      "        about 4t matrix-vector products and almost invariably\n",
      "        produces a norm estimate (which is, in fact, a lower\n",
      "        bound on the norm) correct to within a factor 3.\"\n",
      "        \n",
      "        .. versionadded:: 0.13.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Nicholas J. Higham and Francoise Tisseur (2000),\n",
      "               \"A Block Algorithm for Matrix 1-Norm Estimation,\n",
      "               with an Application to 1-Norm Pseudospectra.\"\n",
      "               SIAM J. Matrix Anal. Appl. Vol. 21, No. 4, pp. 1185-1201.\n",
      "        \n",
      "        .. [2] Awad H. Al-Mohy and Nicholas J. Higham (2009),\n",
      "               \"A new scaling and squaring algorithm for the matrix exponential.\"\n",
      "               SIAM J. Matrix Anal. Appl. Vol. 31, No. 3, pp. 970-989.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import onenormest\n",
      "        >>> A = csc_matrix([[1., 0., 0.], [5., 8., 2.], [0., -1., 0.]], dtype=float)\n",
      "        >>> A.todense()\n",
      "        matrix([[ 1.,  0.,  0.],\n",
      "                [ 5.,  8.,  2.],\n",
      "                [ 0., -1.,  0.]])\n",
      "        >>> onenormest(A)\n",
      "        9.0\n",
      "        >>> np.linalg.norm(A.todense(), ord=1)\n",
      "        9.0\n",
      "    \n",
      "    qmr(A, b, x0=None, tol=1e-05, maxiter=None, M1=None, M2=None, callback=None)\n",
      "        Use Quasi-Minimal Residual iteration to solve ``Ax = b``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, dense matrix, LinearOperator}\n",
      "            The real-valued N-by-N matrix of the linear system.\n",
      "            It is required that the linear operator can produce\n",
      "            ``Ax`` and ``A^T x``.\n",
      "        b : {array, matrix}\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : {array, matrix}\n",
      "            The converged solution.\n",
      "        info : integer\n",
      "            Provides convergence information:\n",
      "                0  : successful exit\n",
      "                >0 : convergence to tolerance not achieved, number of iterations\n",
      "                <0 : illegal input or breakdown\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        x0  : {array, matrix}\n",
      "            Starting guess for the solution.\n",
      "        tol : float\n",
      "            Tolerance to achieve. The algorithm terminates when either the relative\n",
      "            or the absolute residual is below `tol`.\n",
      "        maxiter : integer\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M1 : {sparse matrix, dense matrix, LinearOperator}\n",
      "            Left preconditioner for A.\n",
      "        M2 : {sparse matrix, dense matrix, LinearOperator}\n",
      "            Right preconditioner for A. Used together with the left\n",
      "            preconditioner M1.  The matrix M1*A*M2 should have better\n",
      "            conditioned than A alone.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        LinearOperator\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import qmr\n",
      "        >>> A = csc_matrix([[3, 2, 0], [1, -1, 0], [0, 5, 1]], dtype=float)\n",
      "        >>> b = np.array([2, 4, -1], dtype=float)\n",
      "        >>> x, exitCode = qmr(A, b)\n",
      "        >>> print(exitCode)            # 0 indicates successful convergence\n",
      "        0\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "    \n",
      "    spilu(A, drop_tol=None, fill_factor=None, drop_rule=None, permc_spec=None, diag_pivot_thresh=None, relax=None, panel_size=None, options=None)\n",
      "        Compute an incomplete LU decomposition for a sparse, square matrix.\n",
      "        \n",
      "        The resulting object is an approximation to the inverse of `A`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : (N, N) array_like\n",
      "            Sparse matrix to factorize\n",
      "        drop_tol : float, optional\n",
      "            Drop tolerance (0 <= tol <= 1) for an incomplete LU decomposition.\n",
      "            (default: 1e-4)\n",
      "        fill_factor : float, optional\n",
      "            Specifies the fill ratio upper bound (>= 1.0) for ILU. (default: 10)\n",
      "        drop_rule : str, optional\n",
      "            Comma-separated string of drop rules to use.\n",
      "            Available rules: ``basic``, ``prows``, ``column``, ``area``,\n",
      "            ``secondary``, ``dynamic``, ``interp``. (Default: ``basic,area``)\n",
      "        \n",
      "            See SuperLU documentation for details.\n",
      "        \n",
      "        Remaining other options\n",
      "            Same as for `splu`\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        invA_approx : scipy.sparse.linalg.SuperLU\n",
      "            Object, which has a ``solve`` method.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        splu : complete LU decomposition\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        To improve the better approximation to the inverse, you may need to\n",
      "        increase `fill_factor` AND decrease `drop_tol`.\n",
      "        \n",
      "        This function uses the SuperLU library.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import spilu\n",
      "        >>> A = csc_matrix([[1., 0., 0.], [5., 0., 2.], [0., -1., 0.]], dtype=float)\n",
      "        >>> B = spilu(A)\n",
      "        >>> x = np.array([1., 2., 3.], dtype=float)\n",
      "        >>> B.solve(x)\n",
      "        array([ 1. , -3. , -1.5])\n",
      "        >>> A.dot(B.solve(x))\n",
      "        array([ 1.,  2.,  3.])\n",
      "        >>> B.solve(A.dot(x))\n",
      "        array([ 1.,  2.,  3.])\n",
      "    \n",
      "    splu(A, permc_spec=None, diag_pivot_thresh=None, relax=None, panel_size=None, options={})\n",
      "        Compute the LU decomposition of a sparse, square matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : sparse matrix\n",
      "            Sparse matrix to factorize. Should be in CSR or CSC format.\n",
      "        permc_spec : str, optional\n",
      "            How to permute the columns of the matrix for sparsity preservation.\n",
      "            (default: 'COLAMD')\n",
      "        \n",
      "            - ``NATURAL``: natural ordering.\n",
      "            - ``MMD_ATA``: minimum degree ordering on the structure of A^T A.\n",
      "            - ``MMD_AT_PLUS_A``: minimum degree ordering on the structure of A^T+A.\n",
      "            - ``COLAMD``: approximate minimum degree column ordering\n",
      "        \n",
      "        diag_pivot_thresh : float, optional\n",
      "            Threshold used for a diagonal entry to be an acceptable pivot.\n",
      "            See SuperLU user's guide for details [1]_\n",
      "        relax : int, optional\n",
      "            Expert option for customizing the degree of relaxing supernodes.\n",
      "            See SuperLU user's guide for details [1]_\n",
      "        panel_size : int, optional\n",
      "            Expert option for customizing the panel size.\n",
      "            See SuperLU user's guide for details [1]_\n",
      "        options : dict, optional\n",
      "            Dictionary containing additional expert options to SuperLU.\n",
      "            See SuperLU user guide [1]_ (section 2.4 on the 'Options' argument)\n",
      "            for more details. For example, you can specify\n",
      "            ``options=dict(Equil=False, IterRefine='SINGLE'))``\n",
      "            to turn equilibration off and perform a single iterative refinement.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        invA : scipy.sparse.linalg.SuperLU\n",
      "            Object, which has a ``solve`` method.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        spilu : incomplete LU decomposition\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function uses the SuperLU library.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] SuperLU http://crd.lbl.gov/~xiaoye/SuperLU/\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import splu\n",
      "        >>> A = csc_matrix([[1., 0., 0.], [5., 0., 2.], [0., -1., 0.]], dtype=float)\n",
      "        >>> B = splu(A)\n",
      "        >>> x = np.array([1., 2., 3.], dtype=float)\n",
      "        >>> B.solve(x)\n",
      "        array([ 1. , -3. , -1.5])\n",
      "        >>> A.dot(B.solve(x))\n",
      "        array([ 1.,  2.,  3.])\n",
      "        >>> B.solve(A.dot(x))\n",
      "        array([ 1.,  2.,  3.])\n",
      "    \n",
      "    spsolve(A, b, permc_spec=None, use_umfpack=True)\n",
      "        Solve the sparse linear system Ax=b, where b may be a vector or a matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : ndarray or sparse matrix\n",
      "            The square matrix A will be converted into CSC or CSR form\n",
      "        b : ndarray or sparse matrix\n",
      "            The matrix or vector representing the right hand side of the equation.\n",
      "            If a vector, b.shape must be (n,) or (n, 1).\n",
      "        permc_spec : str, optional\n",
      "            How to permute the columns of the matrix for sparsity preservation.\n",
      "            (default: 'COLAMD')\n",
      "        \n",
      "            - ``NATURAL``: natural ordering.\n",
      "            - ``MMD_ATA``: minimum degree ordering on the structure of A^T A.\n",
      "            - ``MMD_AT_PLUS_A``: minimum degree ordering on the structure of A^T+A.\n",
      "            - ``COLAMD``: approximate minimum degree column ordering\n",
      "        use_umfpack : bool, optional\n",
      "            if True (default) then use umfpack for the solution.  This is\n",
      "            only referenced if b is a vector and ``scikit-umfpack`` is installed.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray or sparse matrix\n",
      "            the solution of the sparse linear equation.\n",
      "            If b is a vector, then x is a vector of size A.shape[1]\n",
      "            If b is a matrix, then x is a matrix of size (A.shape[1], b.shape[1])\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        For solving the matrix expression AX = B, this solver assumes the resulting\n",
      "        matrix X is sparse, as is often the case for very sparse inputs.  If the\n",
      "        resulting X is dense, the construction of this sparse result will be\n",
      "        relatively expensive.  In that case, consider converting A to a dense\n",
      "        matrix and using scipy.linalg.solve or its variants.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import spsolve\n",
      "        >>> A = csc_matrix([[3, 2, 0], [1, -1, 0], [0, 5, 1]], dtype=float)\n",
      "        >>> B = csc_matrix([[2, 0], [-1, 0], [2, 0]], dtype=float)\n",
      "        >>> x = spsolve(A, B)\n",
      "        >>> np.allclose(A.dot(x).todense(), B.todense())\n",
      "        True\n",
      "    \n",
      "    spsolve_triangular(A, b, lower=True, overwrite_A=False, overwrite_b=False)\n",
      "        Solve the equation `A x = b` for `x`, assuming A is a triangular matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : (M, M) sparse matrix\n",
      "            A sparse square triangular matrix. Should be in CSR format.\n",
      "        b : (M,) or (M, N) array_like\n",
      "            Right-hand side matrix in `A x = b`\n",
      "        lower : bool, optional\n",
      "            Whether `A` is a lower or upper triangular matrix.\n",
      "            Default is lower triangular matrix.\n",
      "        overwrite_A : bool, optional\n",
      "            Allow changing `A`. The indices of `A` are going to be sorted and zero\n",
      "            entries are going to be removed.\n",
      "            Enabling gives a performance gain. Default is False.\n",
      "        overwrite_b : bool, optional\n",
      "            Allow overwriting data in `b`.\n",
      "            Enabling gives a performance gain. Default is False.\n",
      "            If `overwrite_b` is True, it should be ensured that\n",
      "            `b` has an appropriate dtype to be able to store the result.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : (M,) or (M, N) ndarray\n",
      "            Solution to the system `A x = b`.  Shape of return matches shape of `b`.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If `A` is singular or not triangular.\n",
      "        ValueError\n",
      "            If shape of `A` or shape of `b` do not match the requirements.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        .. versionadded:: 0.19.0\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csr_matrix\n",
      "        >>> from scipy.sparse.linalg import spsolve_triangular\n",
      "        >>> A = csr_matrix([[3, 0, 0], [1, -1, 0], [2, 0, 1]], dtype=float)\n",
      "        >>> B = np.array([[2, 0], [-1, 0], [2, 0]], dtype=float)\n",
      "        >>> x = spsolve_triangular(A, B)\n",
      "        >>> np.allclose(A.dot(x), B)\n",
      "        True\n",
      "    \n",
      "    svds(A, k=6, ncv=None, tol=0, which='LM', v0=None, maxiter=None, return_singular_vectors=True)\n",
      "        Compute the largest k singular values/vectors for a sparse matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, LinearOperator}\n",
      "            Array to compute the SVD on, of shape (M, N)\n",
      "        k : int, optional\n",
      "            Number of singular values and vectors to compute.\n",
      "            Must be 1 <= k < min(A.shape).\n",
      "        ncv : int, optional\n",
      "            The number of Lanczos vectors generated\n",
      "            ncv must be greater than k+1 and smaller than n;\n",
      "            it is recommended that ncv > 2*k\n",
      "            Default: ``min(n, max(2*k + 1, 20))``\n",
      "        tol : float, optional\n",
      "            Tolerance for singular values. Zero (default) means machine precision.\n",
      "        which : str, ['LM' | 'SM'], optional\n",
      "            Which `k` singular values to find:\n",
      "        \n",
      "                - 'LM' : largest singular values\n",
      "                - 'SM' : smallest singular values\n",
      "        \n",
      "            .. versionadded:: 0.12.0\n",
      "        v0 : ndarray, optional\n",
      "            Starting vector for iteration, of length min(A.shape). Should be an\n",
      "            (approximate) left singular vector if N > M and a right singular\n",
      "            vector otherwise.\n",
      "            Default: random\n",
      "        \n",
      "            .. versionadded:: 0.12.0\n",
      "        maxiter : int, optional\n",
      "            Maximum number of iterations.\n",
      "        \n",
      "            .. versionadded:: 0.12.0\n",
      "        return_singular_vectors : bool or str, optional\n",
      "            - True: return singular vectors (True) in addition to singular values.\n",
      "        \n",
      "            .. versionadded:: 0.12.0\n",
      "        \n",
      "            - \"u\": only return the u matrix, without computing vh (if N > M).\n",
      "            - \"vh\": only return the vh matrix, without computing u (if N <= M).\n",
      "        \n",
      "            .. versionadded:: 0.16.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        u : ndarray, shape=(M, k)\n",
      "            Unitary matrix having left singular vectors as columns.\n",
      "            If `return_singular_vectors` is \"vh\", this variable is not computed,\n",
      "            and None is returned instead.\n",
      "        s : ndarray, shape=(k,)\n",
      "            The singular values.\n",
      "        vt : ndarray, shape=(k, N)\n",
      "            Unitary matrix having right singular vectors as rows.\n",
      "            If `return_singular_vectors` is \"u\", this variable is not computed,\n",
      "            and None is returned instead.\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is a naive implementation using ARPACK as an eigensolver\n",
      "        on A.H * A or A * A.H, depending on which one is more efficient.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import svds, eigs\n",
      "        >>> A = csc_matrix([[1, 0, 0], [5, 0, 2], [0, -1, 0], [0, 0, 3]], dtype=float)\n",
      "        >>> u, s, vt = svds(A, k=2)\n",
      "        >>> s\n",
      "        array([ 2.75193379,  5.6059665 ])\n",
      "        >>> np.sqrt(eigs(A.dot(A.T), k=2)[0]).real\n",
      "        array([ 5.6059665 ,  2.75193379])\n",
      "    \n",
      "    use_solver(**kwargs)\n",
      "        Select default sparse direct solver to be used.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        useUmfpack : bool, optional\n",
      "            Use UMFPACK over SuperLU. Has effect only if scikits.umfpack is\n",
      "            installed. Default: True\n",
      "        assumeSortedIndices : bool, optional\n",
      "            Allow UMFPACK to skip the step of sorting indices for a CSR/CSC matrix.\n",
      "            Has effect only if useUmfpack is True and scikits.umfpack is installed.\n",
      "            Default: False\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The default sparse solver is umfpack when available\n",
      "        (scikits.umfpack is installed). This can be changed by passing\n",
      "        useUmfpack = False, which then causes the always present SuperLU\n",
      "        based solver to be used.\n",
      "        \n",
      "        Umfpack requires a CSR/CSC matrix to have sorted column/row indices. If\n",
      "        sure that the matrix fulfills this, pass ``assumeSortedIndices=True``\n",
      "        to gain some speed.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['ArpackError', 'ArpackNoConvergence', 'LinearOperator', 'Ma...\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "\n",
      "FILE\n",
      "    c:\\programdata\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\__init__.py\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(linalg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19232655  0.63528677]\n",
      " [-0.9621556   0.26010311]\n",
      " [ 0.19232655  0.63528677]\n",
      " [ 0.01666137  0.35379063]]\n"
     ]
    }
   ],
   "source": [
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8332705  5.47929567]\n"
     ]
    }
   ],
   "source": [
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.47503786  0.13474816  0.00822609 -0.47503786  0.00822609  0.09495594\n",
      "  -0.11603761  0.09495594  0.09495594  0.00822609  0.09495594  0.09495594\n",
      "   0.10691838 -0.47503786  0.09495594 -0.47503786]\n",
      " [ 0.1132778   0.39261762  0.15407976  0.1132778   0.15407976  0.27667447\n",
      "   0.34392509  0.27667447  0.27667447  0.15407976  0.27667447  0.27667447\n",
      "   0.38173969  0.1132778   0.27667447  0.1132778 ]]\n"
     ]
    }
   ],
   "source": [
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
